import os
import h5py
import numpy as np
from pathlib import Path
from tqdm import tqdm
import pandas as pd
from concurrent.futures import ProcessPoolExecutor, as_completed
import traceback

class H5FileChecker:
    """H5æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥å·¥å…·"""
    
    def __init__(self, h5_dir, output_dir='./h5_check_results'):
        """
        Args:
            h5_dir: H5æ–‡ä»¶ç›®å½•
            output_dir: æ£€æŸ¥ç»“æœä¿å­˜ç›®å½•
        """
        self.h5_dir = h5_dir
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # æ”¶é›†æ‰€æœ‰H5æ–‡ä»¶
        self.h5_files = self._collect_h5_files()
        print(f"Found {len(self.h5_files)} H5 files in {h5_dir}")
    
    def _collect_h5_files(self):
        """æ”¶é›†æ‰€æœ‰H5æ–‡ä»¶"""
        h5_files = []
        for root, dirs, files in os.walk(self.h5_dir):
            for file in files:
                if file.endswith('.h5'):
                    h5_files.append(os.path.join(root, file))
        return sorted(h5_files)
    
    def check_single_file(self, h5_path):
        """
        æ£€æŸ¥å•ä¸ªH5æ–‡ä»¶
        
        Returns:
            dict: æ£€æŸ¥ç»“æœ
        """
        result = {
            'file_path': h5_path,
            'file_name': os.path.basename(h5_path),
            'status': 'unknown',
            'error': None,
            'file_size_mb': 0,
            'has_features': False,
            'has_coords': False,
            'features_shape': None,
            'coords_shape': None,
            'features_dtype': None,
            'coords_dtype': None,
            'num_patches': 0,
            'shape_match': False,
            'is_empty': False,
            'has_nan': False,
            'has_inf': False,
            'features_min': None,
            'features_max': None,
            'features_mean': None,
        }
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(h5_path):
                result['status'] = 'not_found'
                result['error'] = 'File not found'
                return result
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(h5_path)
            result['file_size_mb'] = file_size / (1024 * 1024)
            
            if file_size == 0:
                result['status'] = 'empty_file'
                result['error'] = 'File size is 0'
                return result
            
            # å°è¯•æ‰“å¼€æ–‡ä»¶
            try:
                with h5py.File(h5_path, 'r') as f:
                    # æ£€æŸ¥å¿…éœ€çš„keys
                    result['has_features'] = 'features' in f
                    result['has_coords'] = 'coords' in f
                    
                    if not result['has_features']:
                        result['status'] = 'missing_features'
                        result['error'] = 'Missing "features" dataset'
                        return result
                    
                    if not result['has_coords']:
                        result['status'] = 'missing_coords'
                        result['error'] = 'Missing "coords" dataset'
                        return result
                    
                    # è¯»å–æ•°æ®
                    features = f['features'][:]
                    coords = f['coords'][:]
                    
                    # è®°å½•å½¢çŠ¶å’Œç±»å‹
                    result['features_shape'] = features.shape
                    result['coords_shape'] = coords.shape
                    result['features_dtype'] = str(features.dtype)
                    result['coords_dtype'] = str(coords.dtype)
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
                    if features.shape[0] == 0:
                        result['status'] = 'empty_data'
                        result['error'] = 'Features array is empty'
                        result['is_empty'] = True
                        return result
                    
                    result['num_patches'] = features.shape[0]
                    
                    # æ£€æŸ¥å½¢çŠ¶æ˜¯å¦åŒ¹é…
                    result['shape_match'] = (features.shape[0] == coords.shape[0])
                    if not result['shape_match']:
                        result['status'] = 'shape_mismatch'
                        result['error'] = f'Shape mismatch: features {features.shape[0]} vs coords {coords.shape[0]}'
                        return result
                    
                    # æ£€æŸ¥NaNå’ŒInf
                    result['has_nan'] = bool(np.isnan(features).any())
                    result['has_inf'] = bool(np.isinf(features).any())
                    
                    if result['has_nan']:
                        result['status'] = 'has_nan'
                        result['error'] = 'Features contain NaN values'
                        return result
                    
                    if result['has_inf']:
                        result['status'] = 'has_inf'
                        result['error'] = 'Features contain Inf values'
                        return result
                    
                    # ç»Ÿè®¡ä¿¡æ¯
                    result['features_min'] = float(np.min(features))
                    result['features_max'] = float(np.max(features))
                    result['features_mean'] = float(np.mean(features))
                    
                    # ä¸€åˆ‡æ­£å¸¸
                    result['status'] = 'valid'
                    
            except OSError as e:
                result['status'] = 'corrupted'
                result['error'] = f'OSError: {str(e)}'
                return result
            
            except Exception as e:
                result['status'] = 'read_error'
                result['error'] = f'{type(e).__name__}: {str(e)}'
                return result
        
        except Exception as e:
            result['status'] = 'unknown_error'
            result['error'] = f'Unexpected error: {str(e)}'
            result['traceback'] = traceback.format_exc()
        
        return result
    
    def check_all_files(self, num_workers=8, save_interval=100):
        """
        æ£€æŸ¥æ‰€æœ‰H5æ–‡ä»¶
        
        Args:
            num_workers: å¹¶è¡Œè¿›ç¨‹æ•°
            save_interval: æ¯æ£€æŸ¥å¤šå°‘ä¸ªæ–‡ä»¶ä¿å­˜ä¸€æ¬¡ç»“æœ
        """
        print(f"\nChecking {len(self.h5_files)} H5 files...")
        print(f"Using {num_workers} workers")
        
        results = []
        
        # ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œæ£€æŸ¥
        with ProcessPoolExecutor(max_workers=num_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(self.check_single_file, h5_path): h5_path 
                for h5_path in self.h5_files
            }
            
            # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
            with tqdm(total=len(self.h5_files), desc="Checking files") as pbar:
                for i, future in enumerate(as_completed(future_to_file)):
                    try:
                        result = future.result()
                        results.append(result)
                    except Exception as e:
                        h5_path = future_to_file[future]
                        results.append({
                            'file_path': h5_path,
                            'file_name': os.path.basename(h5_path),
                            'status': 'check_failed',
                            'error': str(e)
                        })
                    
                    pbar.update(1)
                    
                    # å®šæœŸä¿å­˜ç»“æœ
                    if (i + 1) % save_interval == 0:
                        self._save_intermediate_results(results, i + 1)
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self._save_final_results(results)
        
        return results
    
    def _save_intermediate_results(self, results, count):
        """ä¿å­˜ä¸­é—´ç»“æœ"""
        df = pd.DataFrame(results)
        output_file = os.path.join(self.output_dir, f'intermediate_results_{count}.csv')
        df.to_csv(output_file, index=False)
    
    def _save_final_results(self, results):
        """ä¿å­˜æœ€ç»ˆç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š"""
        df = pd.DataFrame(results)
        
        # ä¿å­˜å®Œæ•´ç»“æœ
        full_output = os.path.join(self.output_dir, 'h5_check_full_results.csv')
        df.to_csv(full_output, index=False)
        print(f"\nâœ… Full results saved to: {full_output}")
        
        # ç»Ÿè®¡å„ç§çŠ¶æ€
        status_counts = df['status'].value_counts()
        
        # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        report = []
        report.append("=" * 80)
        report.append("H5 Files Check Summary")
        report.append("=" * 80)
        report.append(f"Total files checked: {len(results)}")
        report.append(f"\nStatus breakdown:")
        for status, count in status_counts.items():
            percentage = count / len(results) * 100
            report.append(f"  {status:20s}: {count:6d} ({percentage:5.2f}%)")
        
        # æœ‰æ•ˆæ–‡ä»¶ç»Ÿè®¡
        valid_df = df[df['status'] == 'valid']
        if len(valid_df) > 0:
            report.append(f"\nâœ… Valid files: {len(valid_df)}")
            report.append(f"  Total patches: {valid_df['num_patches'].sum():,}")
            report.append(f"  Avg patches per file: {valid_df['num_patches'].mean():.1f}")
            report.append(f"  Min patches: {valid_df['num_patches'].min()}")
            report.append(f"  Max patches: {valid_df['num_patches'].max()}")
            report.append(f"  Total size: {valid_df['file_size_mb'].sum():.2f} MB")
        
        # é—®é¢˜æ–‡ä»¶ç»Ÿè®¡
        problem_df = df[df['status'] != 'valid']
        if len(problem_df) > 0:
            report.append(f"\nâš ï¸  Problem files: {len(problem_df)}")
            
            # ä¿å­˜é—®é¢˜æ–‡ä»¶åˆ—è¡¨
            problem_output = os.path.join(self.output_dir, 'problem_files.csv')
            problem_df.to_csv(problem_output, index=False)
            report.append(f"  Details saved to: {problem_output}")
            
            # æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„
            report.append(f"\n  Problem breakdown:")
            for status in problem_df['status'].unique():
                count = len(problem_df[problem_df['status'] == status])
                report.append(f"    {status}: {count}")
        
        report.append("=" * 80)
        
        # æ‰“å°æŠ¥å‘Š
        report_text = "\n".join(report)
        print("\n" + report_text)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = os.path.join(self.output_dir, 'check_report.txt')
        with open(report_file, 'w') as f:
            f.write(report_text)
        print(f"\nğŸ“„ Report saved to: {report_file}")
        
        return df, problem_df
    
    def quick_check(self, sample_size=100):
        """
        å¿«é€Ÿæ£€æŸ¥ï¼ˆéšæœºæŠ½æ ·ï¼‰
        
        Args:
            sample_size: æŠ½æ ·æ•°é‡
        """
        import random
        
        sample_files = random.sample(self.h5_files, min(sample_size, len(self.h5_files)))
        
        print(f"\nQuick check: sampling {len(sample_files)} files...")
        
        results = []
        for h5_path in tqdm(sample_files, desc="Checking"):
            result = self.check_single_file(h5_path)
            results.append(result)
        
        df = pd.DataFrame(results)
        
        # æ‰“å°å¿«é€Ÿç»Ÿè®¡
        print("\n" + "=" * 60)
        print("Quick Check Results")
        print("=" * 60)
        print(f"Sample size: {len(sample_files)}")
        print("\nStatus breakdown:")
        print(df['status'].value_counts())
        
        valid_count = len(df[df['status'] == 'valid'])
        print(f"\nâœ… Valid: {valid_count}/{len(sample_files)} ({valid_count/len(sample_files)*100:.1f}%)")
        
        if valid_count < len(sample_files):
            print("\nâš ï¸  Found problems! Run full check for details.")
        
        return df


def check_specific_files(file_list, output_dir='./h5_check_results'):
    """
    æ£€æŸ¥æŒ‡å®šçš„H5æ–‡ä»¶åˆ—è¡¨
    
    Args:
        file_list: H5æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_dir: ç»“æœä¿å­˜ç›®å½•
    """
    os.makedirs(output_dir, exist_ok=True)
    
    checker = H5FileChecker.__new__(H5FileChecker)
    checker.output_dir = output_dir
    
    results = []
    for h5_path in tqdm(file_list, desc="Checking files"):
        result = checker.check_single_file(h5_path)
        results.append(result)
    
    df = pd.DataFrame(results)
    
    # ä¿å­˜ç»“æœ
    output_file = os.path.join(output_dir, 'specific_files_check.csv')
    df.to_csv(output_file, index=False)
    
    # æ‰“å°ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("Check Results")
    print("=" * 60)
    print(f"Total files: {len(file_list)}")
    print("\nStatus breakdown:")
    print(df['status'].value_counts())
    print(f"\nResults saved to: {output_file}")
    
    return df


# ============= ä½¿ç”¨ç¤ºä¾‹ =============
if __name__ == '__main__':
    # æ–¹å¼1: æ£€æŸ¥æ•´ä¸ªç›®å½•
    checker = H5FileChecker(
        h5_dir='/home/stat-jijianxin/PFMs/HMU_GC_ALL_H5/features_ctranspath',
        output_dir='./h5_check_results'
    )
    
    # é€‰é¡¹A: å¿«é€Ÿæ£€æŸ¥ï¼ˆæŠ½æ ·100ä¸ªæ–‡ä»¶ï¼‰
    print("\nğŸ” Running quick check...")
    quick_results = checker.quick_check(sample_size=100)
    
    # å¦‚æœå¿«é€Ÿæ£€æŸ¥å‘ç°é—®é¢˜ï¼Œå†è¿è¡Œå®Œæ•´æ£€æŸ¥
    if len(quick_results[quick_results['status'] != 'valid']) > 0:
        print("\nâš ï¸  Quick check found problems. Running full check...")
        user_input = input("Continue with full check? (y/n): ")
        if user_input.lower() == 'y':
            full_results, problem_files = checker.check_all_files(num_workers=8)
    else:
        print("\nâœ… Quick check passed! All sampled files are valid.")
        user_input = input("Run full check anyway? (y/n): ")
        if user_input.lower() == 'y':
            full_results, problem_files = checker.check_all_files(num_workers=8)
    
    # æ–¹å¼2: åªæ£€æŸ¥ç‰¹å®šæ–‡ä»¶
    # specific_files = [
    #     '/path/to/file1.h5',
    #     '/path/to/file2.h5',
    # ]
    # results = check_specific_files(specific_files)
    
    # æ–¹å¼3: æ£€æŸ¥CSVä¸­åˆ—å‡ºçš„æ–‡ä»¶
    # import pandas as pd
    # csv_df = pd.read_csv('your_csv_file.csv')
    # slide_ids = csv_df['slide_id'].tolist()
    # h5_paths = [os.path.join(h5_dir, f"{sid}.h5") for sid in slide_ids]
    # results = check_specific_files(h5_paths)
