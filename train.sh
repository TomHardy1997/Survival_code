#!/bin/bash

# ============================================================
# ç”Ÿå­˜åˆ†æè®­ç»ƒè„šæœ¬ - å®Œæ•´å¼ºåŒ–ç‰ˆ (è§£å†³ /tmp æ»¡é—®é¢˜)
# ============================================================

# ============================================================
# ğŸ”¥ å…³é”®: ä¿®æ”¹æ‰€æœ‰ç¼“å­˜è·¯å¾„åˆ° home ç›®å½• (é¿å… /tmp æ»¡)
# ============================================================
export HOME_CACHE="/home/stat-jijianxin/.cache"
mkdir -p $HOME_CACHE

export TRITON_CACHE_DIR="$HOME_CACHE/triton"
export TORCH_COMPILE_CACHE_DIR="$HOME_CACHE/torch_compile"
export TRANSFORMERS_CACHE="$HOME_CACHE/transformers"
export HF_HOME="$HOME_CACHE/huggingface"

mkdir -p $TRITON_CACHE_DIR
mkdir -p $TORCH_COMPILE_CACHE_DIR

# æ¸…ç†æ—§ç¼“å­˜
rm -rf $TRITON_CACHE_DIR/* 2>/dev/null || true

echo "âœ“ ç¼“å­˜è·¯å¾„å·²è®¾ç½®åˆ°: $HOME_CACHE"

# ============================================================
# ğŸ”¥ NCCL é…ç½®
# ============================================================
export NCCL_SOCKET_IFNAME=lo
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=0
export NCCL_SHM_DISABLE=0
export NCCL_BLOCKING_WAIT=1
export NCCL_ASYNC_ERROR_HANDLING=1
export NCCL_DEBUG=WARN
export NCCL_TIMEOUT=1800  # 30åˆ†é’Ÿè¶…æ—¶

# ============================================================
# GPU é…ç½®
# ============================================================
export CUDA_VISIBLE_DEVICES=0,1
NUM_GPUS=2
MASTER_ADDR=127.0.0.1
BASE_PORT=29500  # åŠ¨æ€ç«¯å£åŸºå‡†

# ============================================================
# æ•°æ®è·¯å¾„
# ============================================================
CSV_PATH="/home/stat-jijianxin/PFMs/Survival_code/csv_file/hmu_survival_with_slides.csv"
H5_DIR="/home/stat-jijianxin/PFMs/HMU_GC_ALL_H5/features_ctranspath"
EXTERNAL_CSV="/home/stat-jijianxin/PFMs/Survival_code/csv_file/tcga_survival_matched.csv"
EXTERNAL_H5="/home/stat-jijianxin/PFMs/TRIDENT/tcga_filtered/20x_512px_0px_overlap/features_ctranspath"

# ============================================================
# æ¨¡å‹å‚æ•°
# ============================================================
IN_DIM=768
N_CLASSES=4
DROPOUT=0.25
ACT="gelu"
MAMBA_LAYER=2

# ============================================================
# è®­ç»ƒå‚æ•°
# ============================================================
MAX_EPOCHS=100
WEIGHT_DECAY=1e-5
OPTIMIZER="adamw"

# ============================================================
# æŸå¤±å‡½æ•°å‚æ•°
# ============================================================
LOSS="combined"
ALPHA_SURV=0.35
RANKING_WEIGHT=0.1
RANKING_MARGIN=0.0
GC=1

# ============================================================
# K-Foldå‚æ•°
# ============================================================
K_FOLD=10
VAL_RATIO=0.1
TEST_RATIO=0.1

# ============================================================
# æ—©åœå‚æ•°
# ============================================================
WARMUP=5
PATIENCE=15
STOP_EPOCH=20

# ============================================================
# å…¶ä»–å‚æ•°
# ============================================================
NUM_WORKERS=0
SEED=42

# ============================================================
# ğŸ”¥ å‚æ•°ç»„åˆ
# ============================================================
PARAM_GROUPS=(
  "8 2e-4 results_hmu_tcga_ddp_batch8_lr2e4"
  "4 1e-4 results_hmu_tcga_ddp_batch4_lr1e4"
  "16 5e-4 results_hmu_tcga_ddp_batch16_lr5e4"
)

# ============================================================
# ğŸ”¥ å¼ºåŒ–æ¸…ç†å‡½æ•°
# ============================================================
cleanup_resources() {
    echo "ğŸ§¹ å¼ºåŒ–èµ„æºæ¸…ç†..."
    
    # 1. æ€æ­»æ‰€æœ‰ç›¸å…³è¿›ç¨‹
    pkill -9 -f "torchrun" 2>/dev/null || true
    pkill -9 -f "main.py" 2>/dev/null || true
    pkill -9 -f "python.*main.py" 2>/dev/null || true
    
    # 2. æ¸…ç† CUDA ç¼“å­˜
    python3 << 'PYEOF'
import torch
import gc
if torch.cuda.is_available():
    for i in range(torch.cuda.device_count()):
        with torch.cuda.device(i):
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
gc.collect()
print("âœ“ CUDA ç¼“å­˜å·²æ¸…ç†")
PYEOF
    
    # 3. æ¸…ç†å…±äº«å†…å­˜
    rm -rf /dev/shm/torch_* 2>/dev/null || true
    
    # 4. ğŸ”¥ æ¸…ç† Triton ç¼“å­˜ (å…³é”®!)
    rm -rf $TRITON_CACHE_DIR/* 2>/dev/null || true
    
    # 5. ğŸ”¥ æ¸…ç† /tmp ä¸­çš„ä¸´æ—¶æ–‡ä»¶
    rm -rf /tmp/triton_cache_rank_* 2>/dev/null || true
    rm -rf /tmp/torch_* 2>/dev/null || true
    
    # 6. ç­‰å¾…ç«¯å£é‡Šæ”¾
    sleep 3
    
    echo "âœ“ èµ„æºæ¸…ç†å®Œæˆ"
}

# ============================================================
# ğŸ”¥ æ£€æŸ¥ç«¯å£å‡½æ•°
# ============================================================
wait_for_port() {
    local port=$1
    local max_wait=30
    local waited=0
    
    while netstat -tuln 2>/dev/null | grep -q ":$port "; do
        if [ $waited -ge $max_wait ]; then
            echo "âš ï¸  ç«¯å£ $port ä»è¢«å ç”¨ï¼Œå¼ºåˆ¶æ¸…ç†..."
            fuser -k $port/tcp 2>/dev/null || true
            sleep 2
            break
        fi
        echo "â³ ç­‰å¾…ç«¯å£ $port é‡Šæ”¾... ($waited/$max_wait)"
        sleep 1
        waited=$((waited + 1))
    done
}

# ============================================================
# ç¯å¢ƒæ£€æŸ¥
# ============================================================
echo ""
echo "============================================================"
echo "ğŸ” ç¯å¢ƒæ£€æŸ¥"
echo "============================================================"
python3 --version
python3 -c "import torch; print(f'PyTorch: {torch.__version__}')"
python3 -c "import torch; print(f'CUDA å¯ç”¨: {torch.cuda.is_available()}')"
python3 -c "import torch; print(f'GPU æ•°é‡: {torch.cuda.device_count()}')"
echo "ç¼“å­˜ç›®å½•: $TRITON_CACHE_DIR"

if [ ! -f "$CSV_PATH" ]; then
    echo "âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: $CSV_PATH"
    exit 1
fi
if [ ! -d "$H5_DIR" ]; then
    echo "âŒ H5ç›®å½•ä¸å­˜åœ¨: $H5_DIR"
    exit 1
fi

# æ£€æŸ¥ç£ç›˜ç©ºé—´
echo ""
echo "ç£ç›˜ç©ºé—´æ£€æŸ¥:"
df -h /home/stat-jijianxin | tail -1
df -h /tmp | tail -1

echo ""
echo "âœ“ ç¯å¢ƒæ£€æŸ¥é€šè¿‡"
echo ""

# ============================================================
# ğŸ”¥ ä¸»å¾ªç¯
# ============================================================
GLOBAL_START_TIME=$(date +%s)

for PARAM_GROUP in "${PARAM_GROUPS[@]}"; do
  IFS=' ' read -r BATCH_SIZE LR RESULTS_DIR <<< "$PARAM_GROUP"
  
  echo ""
  echo "============================================================"
  echo "ğŸš€ å¼€å§‹è®­ç»ƒå‚æ•°ç»„"
  echo "============================================================"
  echo "Batch Size: $BATCH_SIZE"
  echo "Learning Rate: $LR"
  echo "ç»“æœç›®å½•: $RESULTS_DIR"
  echo "============================================================"
  
  mkdir -p $RESULTS_DIR
  TOTAL_START_TIME=$(date +%s)
  FAILED_FOLDS=()

  # ============================================================
  # Fold å¾ªç¯
  # ============================================================
  for FOLD in $(seq 0 $((K_FOLD-1))); do
      echo ""
      echo "============================================================"
      echo "ğŸ“Š è®­ç»ƒ Fold $FOLD / $((K_FOLD-1))"
      echo "============================================================"
      
      # ğŸ”¥ åŠ¨æ€ç«¯å£ (é¿å…å†²çª)
      MASTER_PORT=$((BASE_PORT + FOLD))
      
      # ğŸ”¥ æ¸…ç†èµ„æº
      cleanup_resources
      
      # ğŸ”¥ ç­‰å¾…ç«¯å£
      wait_for_port $MASTER_PORT
      
      FOLD_START_TIME=$(date +%s)
      
      # æ„å»ºå‘½ä»¤
      CMD="main.py \
          --csv_path $CSV_PATH \
          --h5_dir $H5_DIR \
          --in_dim $IN_DIM \
          --n_classes $N_CLASSES \
          --dropout $DROPOUT \
          --act $ACT \
          --mamba_layer $MAMBA_LAYER \
          --batch_size $BATCH_SIZE \
          --max_epochs $MAX_EPOCHS \
          --lr $LR \
          --weight_decay $WEIGHT_DECAY \
          --optimizer $OPTIMIZER \
          --loss $LOSS \
          --alpha_surv $ALPHA_SURV \
          --ranking_weight $RANKING_WEIGHT \
          --ranking_margin $RANKING_MARGIN \
          --gc $GC \
          --k_fold $K_FOLD \
          --fold $FOLD \
          --val_ratio $VAL_RATIO \
          --test_ratio $TEST_RATIO \
          --warmup $WARMUP \
          --patience $PATIENCE \
          --stop_epoch $STOP_EPOCH \
          --results_dir $RESULTS_DIR \
          --num_workers $NUM_WORKERS \
          --seed $SEED"
      
      if [ ! -z "$EXTERNAL_CSV" ] && [ ! -z "$EXTERNAL_H5" ]; then
          CMD="$CMD --external_csv_path $EXTERNAL_CSV --external_h5_dir $EXTERNAL_H5"
      fi
      
      echo "å¯åŠ¨è®­ç»ƒ (ç«¯å£: $MASTER_PORT)..."
      
      # ğŸ”¥ å¯åŠ¨è®­ç»ƒ (å¸¦è¶…æ—¶ä¿æŠ¤)
      timeout 7200 torchrun \
          --nproc_per_node=$NUM_GPUS \
          --master_addr=$MASTER_ADDR \
          --master_port=$MASTER_PORT \
          --node_rank=0 \
          --nnodes=1 \
          $CMD
      
      EXIT_CODE=$?
      
      FOLD_END_TIME=$(date +%s)
      FOLD_ELAPSED=$((FOLD_END_TIME - FOLD_START_TIME))
      
      echo ""
      if [ $EXIT_CODE -eq 0 ]; then
          echo "âœ… Fold $FOLD è®­ç»ƒæˆåŠŸ"
          echo "è€—æ—¶: $((FOLD_ELAPSED/60)) åˆ†é’Ÿ $((FOLD_ELAPSED%60)) ç§’"
      elif [ $EXIT_CODE -eq 124 ]; then
          echo "â±ï¸  Fold $FOLD è®­ç»ƒè¶…æ—¶ (2å°æ—¶)"
          FAILED_FOLDS+=($FOLD)
      else
          echo "âŒ Fold $FOLD è®­ç»ƒå¤±è´¥ (é€€å‡ºç : $EXIT_CODE)"
          FAILED_FOLDS+=($FOLD)
      fi
      
      # ğŸ”¥ Fold é—´æ¸…ç†
      cleanup_resources
      echo "â³ ç­‰å¾… 15 ç§’åå¼€å§‹ä¸‹ä¸€ä¸ª Fold..."
      sleep 15
  done

  # ============================================================
  # æ±‡æ€»ç»“æœ
  # ============================================================
  echo ""
  echo "============================================================"
  echo "ğŸ“Š æ±‡æ€»å½“å‰å‚æ•°ç»„ K-Fold ç»“æœ"
  echo "============================================================"
  
  export RESULTS_DIR
  export K_FOLD
  
  python3 << 'EOF'
import os
import pickle
import pandas as pd
import numpy as np

results_dir = os.environ['RESULTS_DIR']
k_fold = int(os.environ['K_FOLD'])

all_results = []
missing_folds = []

for fold in range(k_fold):
    results_file = os.path.join(results_dir, f'fold_{fold}', 'results.pkl')
    if os.path.exists(results_file):
        try:
            with open(results_file, 'rb') as f:
                all_results.append(pickle.load(f))
        except Exception as e:
            print(f"âš ï¸  Fold {fold} ç»“æœæ–‡ä»¶æŸå: {e}")
            missing_folds.append(fold)
    else:
        print(f"âš ï¸  Fold {fold} ç»“æœæ–‡ä»¶ä¸å­˜åœ¨")
        missing_folds.append(fold)

if all_results:
    val_ci = [r['val_cindex'] for r in all_results]
    test_ci = [r['test_cindex'] for r in all_results]
    
    df = pd.DataFrame({
        'fold': list(range(len(all_results))),
        'val_cindex': val_ci,
        'test_cindex': test_ci
    })
    
    if 'external_cindex' in all_results[0]:
        ext_ci = [r['external_cindex'] for r in all_results]
        df['external_cindex'] = ext_ci
    
    summary_path = os.path.join(results_dir, 'summary.csv')
    df.to_csv(summary_path, index=False)
    
    print(f'\nâœ“ å®Œæˆ {len(all_results)}/{k_fold} Folds')
    print(f'\néªŒè¯é›† C-index: {np.mean(val_ci):.4f} Â± {np.std(val_ci):.4f}')
    print(f'æµ‹è¯•é›† C-index: {np.mean(test_ci):.4f} Â± {np.std(test_ci):.4f}')
    
    if 'external_cindex' in all_results[0]:
        print(f'å¤–éƒ¨é›† C-index: {np.mean(ext_ci):.4f} Â± {np.std(ext_ci):.4f}')
    
    print('\nè¯¦ç»†ç»“æœ:')
    print(df.to_string(index=False))
    print(f'\nç»“æœå·²ä¿å­˜è‡³: {summary_path}')
else:
    print('\nâŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å®Œæˆçš„ Fold ç»“æœ')
EOF

  TOTAL_END_TIME=$(date +%s)
  TOTAL_ELAPSED=$((TOTAL_END_TIME - TOTAL_START_TIME))
  
  echo ""
  echo "============================================================"
  if [ ${#FAILED_FOLDS[@]} -eq 0 ]; then
      echo "âœ… å½“å‰å‚æ•°ç»„æ‰€æœ‰ Fold è®­ç»ƒæˆåŠŸ"
  else
      echo "âš ï¸  å½“å‰å‚æ•°ç»„éƒ¨åˆ† Fold è®­ç»ƒå¤±è´¥: ${FAILED_FOLDS[@]}"
  fi
  echo "============================================================"
  echo "å½“å‰å‚æ•°ç»„æ€»è€—æ—¶: $((TOTAL_ELAPSED/3600))h $((TOTAL_ELAPSED%3600/60))m $((TOTAL_ELAPSED%60))s"
  echo "ç»“æœä¿å­˜è‡³: $RESULTS_DIR"
  echo ""
  
  # ğŸ”¥ å‚æ•°ç»„é—´å¼ºåŒ–æ¸…ç†
  cleanup_resources
  echo "â³ å‚æ•°ç»„åˆ‡æ¢ï¼Œç­‰å¾… 30 ç§’ï¼Œç¡®ä¿èµ„æºå®Œå…¨é‡Šæ”¾..."
  sleep 30
  echo "âœ“ å‚æ•°ç»„é—´èµ„æºæ¸…ç†å®Œæˆ"
  echo ""
done

# ============================================================
# æœ€ç»ˆç»Ÿè®¡
# ============================================================
GLOBAL_END_TIME=$(date +%s)
GLOBAL_ELAPSED=$((GLOBAL_END_TIME - GLOBAL_START_TIME))

echo ""
echo "============================================================"
echo "âœ… æ‰€æœ‰å‚æ•°ç»„è®­ç»ƒå®Œæˆ!"
echo "============================================================"
echo "æ‰€æœ‰å‚æ•°ç»„æ€»è€—æ—¶: $((GLOBAL_ELAPSED/3600))h $((GLOBAL_ELAPSED%3600/60))m $((GLOBAL_ELAPSED%60))s"
echo "============================================================"
echo ""
