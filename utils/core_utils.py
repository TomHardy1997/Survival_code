"""
ç”Ÿå­˜åˆ†æè®­ç»ƒæ¡†æ¶ - DDP å¤šGPUç‰ˆæœ¬
æ”¯æŒ Mamba2MIL çš„åˆ†å¸ƒå¼è®­ç»ƒ
"""
import os
import numpy as np
import torch
import torch.nn as nn
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
from sksurv.metrics import concordance_index_censored
import pandas as pd
from tqdm import tqdm
import pickle
from argparse import Namespace


# ===================== DDP å·¥å…·å‡½æ•° =====================
def setup_ddp():
    """åˆå§‹åŒ– DDP ç¯å¢ƒ"""
    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
        rank = int(os.environ['RANK'])
        world_size = int(os.environ['WORLD_SIZE'])
        local_rank = int(os.environ['LOCAL_RANK'])
        
        # åˆå§‹åŒ–è¿›ç¨‹ç»„
        dist.init_process_group(backend='nccl')
        
        # è®¾ç½®å½“å‰è¿›ç¨‹çš„GPU
        torch.cuda.set_device(local_rank)
        
        return rank, local_rank, world_size
    else:
        # å•GPUæ¨¡å¼
        return 0, 0, 1


def cleanup_ddp():
    """æ¸…ç† DDP"""
    if dist.is_initialized():
        dist.destroy_process_group()


def is_main_process():
    """åˆ¤æ–­æ˜¯å¦æ˜¯ä¸»è¿›ç¨‹"""
    return not dist.is_initialized() or dist.get_rank() == 0


def print_rank0(*args, **kwargs):
    """åªåœ¨ä¸»è¿›ç¨‹æ‰“å°"""
    if is_main_process():
        print(*args, **kwargs)


# ===================== æ—©åœæœºåˆ¶ =====================
class EarlyStopping:
    """åŸºäºC-Indexçš„æ—©åœ"""
    def __init__(self, warmup=5, patience=15, stop_epoch=20, verbose=False):
        self.warmup = warmup
        self.patience = patience
        self.stop_epoch = stop_epoch
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.best_cindex = 0

    def __call__(self, epoch, val_cindex, model, ckpt_name='checkpoint.pt'):
        score = val_cindex

        if epoch < self.warmup:
            pass
        elif self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_cindex, model, ckpt_name)
        elif score <= self.best_score:
            self.counter += 1
            if self.verbose:
                print_rank0(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience and epoch > self.stop_epoch:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_cindex, model, ckpt_name)
            self.counter = 0

    def save_checkpoint(self, val_cindex, model, ckpt_name):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹ - åªåœ¨ä¸»è¿›ç¨‹ä¿å­˜"""
        if not is_main_process():
            return
            
        if self.verbose:
            print_rank0(f'C-Index increased ({self.best_cindex:.4f} --> {val_cindex:.4f}). Saving model...')
        
        # å¤„ç† DDP æ¨¡å‹
        if isinstance(model, DDP):
            torch.save(model.module.state_dict(), ckpt_name)
        else:
            torch.save(model.state_dict(), ckpt_name)
        
        self.best_cindex = val_cindex


# ===================== æ•°æ®åŠ è½½å™¨ =====================
def get_split_loader(split_dataset, batch_size=1, num_workers=4, training=False, 
                     use_ddp=False, world_size=1, rank=0):
    """
    åˆ›å»ºæ•°æ®åŠ è½½å™¨ - DDP ç‰ˆæœ¬
    
    Args:
        split_dataset: æ•°æ®é›†
        batch_size: æ‰¹å¤§å°
        num_workers: å·¥ä½œè¿›ç¨‹æ•°
        training: æ˜¯å¦æ˜¯è®­ç»ƒæ¨¡å¼
        use_ddp: æ˜¯å¦ä½¿ç”¨ DDP
        world_size: æ€»è¿›ç¨‹æ•°
        rank: å½“å‰è¿›ç¨‹rank
    """
    from dataset.dataset_h5 import custom_collate_fn
    
    if training:
        # è®­ç»ƒæ¨¡å¼
        if use_ddp:
            # DDP: ä½¿ç”¨ DistributedSampler
            sampler = DistributedSampler(
                split_dataset,
                num_replicas=world_size,
                rank=rank,
                shuffle=True,
                drop_last=False
            )
            loader = DataLoader(
                split_dataset,
                batch_size=batch_size,
                sampler=sampler,
                num_workers=num_workers,
                collate_fn=custom_collate_fn,
                pin_memory=True,
                drop_last=False
            )
        else:
            # å•GPU: æ­£å¸¸ shuffle
            loader = DataLoader(
                split_dataset,
                batch_size=batch_size,
                shuffle=True,
                num_workers=num_workers,
                collate_fn=custom_collate_fn,
                pin_memory=True,
                drop_last=False
            )
    else:
        # éªŒè¯/æµ‹è¯•æ¨¡å¼: batch_size=1, ä¸éœ€è¦åˆ†å¸ƒå¼
        loader = DataLoader(
            split_dataset,
            batch_size=1,
            shuffle=False,
            num_workers=num_workers,
            collate_fn=None,
            pin_memory=True,
            drop_last=False
        )
    
    return loader


# ===================== è®­ç»ƒå¾ªç¯ =====================
def train_loop(epoch, model, loader, optimizer, loss_fn, device, gc=1, 
               use_ddp=False, rank=0):
    """è®­ç»ƒä¸€ä¸ªepoch - DDP ç‰ˆæœ¬"""
    model.train()
    train_loss = 0.
    
    # å¦‚æœä½¿ç”¨ DDPï¼Œè®¾ç½® epoch ç”¨äº shuffle
    if use_ddp and hasattr(loader.sampler, 'set_epoch'):
        loader.sampler.set_epoch(epoch)
    
    # å¦‚æœæ˜¯ç»„åˆæŸå¤±,è®°å½•å„åˆ†é‡
    is_combined = hasattr(loss_fn, 'get_loss_components')
    if is_combined:
        main_losses = []
        ranking_losses = []
    
    all_risk_scores = []
    all_censorships = []
    all_event_times = []
    
    # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
    if is_main_process():
        pbar = tqdm(enumerate(loader), total=len(loader), desc=f'Epoch {epoch} [Train]')
    else:
        pbar = enumerate(loader)
    
    for batch_idx, batch_data in pbar:
        if batch_data is None:
            continue
        
        (patient_list, gender, age, label, sur_time, censor, 
         features, coords, num_patches, mask) = batch_data
        
        features = features.to(device)
        mask = mask.to(device)
        label = label.to(device)
        censor = censor.to(device)
        
        batch_size = features.size(0)
        
        # å‰å‘ä¼ æ’­
        hazards, S, Y_hat, A, h = model(features, mask=mask)
        
        # è®¡ç®—æŸå¤±
        loss = 0
        for i in range(batch_size):
            loss += loss_fn(
                hazards=hazards[i:i+1],
                S=S[i:i+1],
                Y=label[i:i+1],
                c=censor[i:i+1]
            )
        loss = loss / batch_size
        loss_value = loss.item()
        
        # è®°å½•æŸå¤±åˆ†é‡
        if is_combined:
            loss_components = loss_fn.get_loss_components(hazards, S, label, censor)
            main_losses.append(loss_components['main_loss'])
            ranking_losses.append(loss_components['ranking_loss'])
        
        # è®¡ç®—é£é™©åˆ†æ•°
        risk = -torch.sum(S, dim=1).detach().cpu().numpy()
        all_risk_scores.extend(risk)
        all_censorships.extend(censor.cpu().numpy())
        all_event_times.extend(sur_time.numpy())
        
        train_loss += loss_value
        
        # åå‘ä¼ æ’­
        loss = loss / gc
        loss.backward()
        
        if (batch_idx + 1) % gc == 0:
            optimizer.step()
            optimizer.zero_grad()
        
        # æ›´æ–°è¿›åº¦æ¡ (åªåœ¨ä¸»è¿›ç¨‹)
        if is_main_process():
            if is_combined:
                pbar.set_postfix({
                    'loss': f'{loss_value:.4f}',
                    'main': f'{loss_components["main_loss"]:.4f}',
                    'rank': f'{loss_components["ranking_loss"]:.4f}'
                })
            else:
                pbar.set_postfix({'loss': f'{loss_value:.4f}'})
    
    # æœ€åä¸€æ­¥
    if len(loader) % gc != 0:
        optimizer.step()
        optimizer.zero_grad()
    
    # ğŸ”¥ DDP: åŒæ­¥æ‰€æœ‰è¿›ç¨‹çš„æŒ‡æ ‡
    if use_ddp:
        # æ”¶é›†æ‰€æœ‰ GPU çš„ç»“æœ
        train_loss_tensor = torch.tensor([train_loss], device=device)
        dist.all_reduce(train_loss_tensor, op=dist.ReduceOp.SUM)
        train_loss = train_loss_tensor.item() / dist.get_world_size()
        
        # æ”¶é›†æ‰€æœ‰ GPU çš„é¢„æµ‹ç»“æœ
        all_risk_scores = torch.tensor(all_risk_scores, device=device)
        all_censorships = torch.tensor(all_censorships, device=device)
        all_event_times = torch.tensor(all_event_times, device=device)
        
        # gather åˆ°ä¸»è¿›ç¨‹
        if is_main_process():
            gathered_risks = [torch.zeros_like(all_risk_scores) for _ in range(dist.get_world_size())]
            gathered_censors = [torch.zeros_like(all_censorships) for _ in range(dist.get_world_size())]
            gathered_times = [torch.zeros_like(all_event_times) for _ in range(dist.get_world_size())]
        else:
            gathered_risks = None
            gathered_censors = None
            gathered_times = None
        
        dist.gather(all_risk_scores, gathered_risks, dst=0)
        dist.gather(all_censorships, gathered_censors, dst=0)
        dist.gather(all_event_times, gathered_times, dst=0)
        
        if is_main_process():
            all_risk_scores = torch.cat(gathered_risks).cpu().numpy()
            all_censorships = torch.cat(gathered_censors).cpu().numpy()
            all_event_times = torch.cat(gathered_times).cpu().numpy()
    else:
        train_loss /= len(loader)
        all_risk_scores = np.array(all_risk_scores)
        all_censorships = np.array(all_censorships)
        all_event_times = np.array(all_event_times)
    
    # è®¡ç®— C-Index (åªåœ¨ä¸»è¿›ç¨‹)
    if is_main_process():
        c_index = concordance_index_censored(
            (1 - all_censorships).astype(bool),
            all_event_times,
            all_risk_scores,
            tied_tol=1e-08
        )[0]
        
        # æ‰“å°è¯¦ç»†ä¿¡æ¯
        if is_combined:
            print_rank0(f'Epoch {epoch}: train_loss={train_loss:.4f} '
                  f'(main={np.mean(main_losses):.4f}, rank={np.mean(ranking_losses):.4f}), '
                  f'train_c_index={c_index:.4f}')
        else:
            print_rank0(f'Epoch {epoch}: train_loss={train_loss:.4f}, train_c_index={c_index:.4f}')
    else:
        c_index = 0.0
    
    # å¹¿æ’­ c_index åˆ°æ‰€æœ‰è¿›ç¨‹
    if use_ddp:
        c_index_tensor = torch.tensor([c_index], device=device)
        dist.broadcast(c_index_tensor, src=0)
        c_index = c_index_tensor.item()
    
    return train_loss, c_index


# ===================== éªŒè¯å¾ªç¯ =====================
def validate(epoch, model, loader, loss_fn, device):
    """éªŒè¯ä¸€ä¸ªepoch - åªåœ¨ä¸»è¿›ç¨‹è¿è¡Œ"""
    if not is_main_process():
        return 0.0, 0.0
    
    model.eval()
    val_loss = 0.
    
    all_risk_scores = []
    all_censorships = []
    all_event_times = []
    
    pbar = tqdm(enumerate(loader), total=len(loader), desc=f'Epoch {epoch} [Val]')
    
    with torch.no_grad():
        for batch_idx, batch in pbar:
            features = batch['features'].to(device)
            label = batch['label'].to(device)
            event_time = batch['survival_time']
            c = batch['censorship'].to(device)
            
            # å‰å‘ä¼ æ’­
            hazards, S, Y_hat, _, _ = model(features)
            
            # è®¡ç®—æŸå¤±
            loss = loss_fn(hazards=hazards, S=S, Y=label, c=c)
            loss_value = loss.item()
            
            # è®¡ç®—é£é™©åˆ†æ•°
            risk = -torch.sum(S, dim=1).cpu().numpy()[0]
            all_risk_scores.append(risk)
            all_censorships.append(c.item())
            all_event_times.append(event_time.item())
            
            val_loss += loss_value
            pbar.set_postfix({'loss': f'{loss_value:.4f}'})
    
    val_loss /= len(loader)
    c_index = concordance_index_censored(
        (1 - np.array(all_censorships)).astype(bool),
        np.array(all_event_times),
        np.array(all_risk_scores),
        tied_tol=1e-08
    )[0]
    
    print_rank0(f'Epoch {epoch}: val_loss={val_loss:.4f}, val_c_index={c_index:.4f}')
    
    return val_loss, c_index


# ===================== æµ‹è¯•å‡½æ•° =====================
def test(model, loader, device):
    """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ - åªåœ¨ä¸»è¿›ç¨‹è¿è¡Œ"""
    if not is_main_process():
        return {}, 0.0
    
    model.eval()
    
    all_risk_scores = []
    all_censorships = []
    all_event_times = []
    patient_results = {}
    
    pbar = tqdm(enumerate(loader), total=len(loader), desc='Testing')
    
    with torch.no_grad():
        for batch_idx, batch in pbar:
            case_id = batch['case_id'][0]
            features = batch['features'].to(device)
            label = batch['label']
            event_time = batch['survival_time']
            c = batch['censorship']
            
            # å‰å‘ä¼ æ’­
            hazards, S, Y_hat, _, _ = model(features)
            
            # è®¡ç®—é£é™©åˆ†æ•°
            risk = -torch.sum(S, dim=1).cpu().numpy()[0]
            
            all_risk_scores.append(risk)
            all_censorships.append(c.item())
            all_event_times.append(event_time.item())
            
            # ä¿å­˜æ‚£è€…ç»“æœ
            patient_results[case_id] = {
                'case_id': case_id,
                'risk': risk,
                'disc_label': label.item(),
                'survival': event_time.item(),
                'censorship': c.item(),
                'hazards': hazards.cpu().numpy(),
                'S': S.cpu().numpy()
            }
    
    c_index = concordance_index_censored(
        (1 - np.array(all_censorships)).astype(bool),
        np.array(all_event_times),
        np.array(all_risk_scores),
        tied_tol=1e-08
    )[0]
    
    print_rank0(f'Test C-Index: {c_index:.4f}')
    
    return patient_results, c_index


# ===================== ä¸»è®­ç»ƒå‡½æ•° =====================
def train_survival(args):
    """ä¸»è®­ç»ƒå‡½æ•° - DDP ç‰ˆæœ¬"""
    
    # ğŸ”¥ Step 1: åˆå§‹åŒ– DDP
    rank, local_rank, world_size = setup_ddp()
    use_ddp = world_size > 1
    
    # è®¾ç½®è®¾å¤‡
    if torch.cuda.is_available():
        device = torch.device(f'cuda:{local_rank}')
    else:
        device = torch.device('cpu')
    
    # ğŸ”¥ è®¾ç½® Triton ç¼“å­˜ç›®å½•ï¼ˆé¿å…å¤šè¿›ç¨‹å†²çªï¼‰
    os.environ['TRITON_CACHE_DIR'] = f'/tmp/triton_cache_rank_{rank}'
    
    print_rank0('\n' + '='*60)
    print_rank0(f'Training Fold {args.fold}')
    if use_ddp:
        print_rank0(f'Using DDP with {world_size} GPUs (Rank {rank}/{world_size})')
    print_rank0('='*60)
    
    # åˆ›å»ºç»“æœç›®å½• (åªåœ¨ä¸»è¿›ç¨‹)
    fold_dir = os.path.join(args.results_dir, f'fold_{args.fold}')
    if is_main_process():
        os.makedirs(fold_dir, exist_ok=True)
    
    # ğŸ”¥ DDP: åŒæ­¥æ‰€æœ‰è¿›ç¨‹
    if use_ddp:
        dist.barrier()
    
    # ========== 1. åŠ è½½æ•°æ®é›† ==========
    print_rank0('\n[1/7] Loading dataset...')
    from dataset.dataset_h5 import PrognosisDataset
    
    dataset = PrognosisDataset(
        csv_path=args.csv_path,
        h5_dir=args.h5_dir,
        label_col=args.label_col,
        use_cache=True,
        print_info=is_main_process()
    )
    
    # åˆ›å»ºK-foldåˆ†å‰²
    if not hasattr(dataset, 'splits'):
        dataset.create_splits(
            n_splits=args.k_fold,
            val_ratio=args.val_ratio,
            test_ratio=args.test_ratio,
            stratify=True
        )
    
    dataset.set_split(fold=args.fold)
    
    train_dataset = dataset.get_split_dataset('train')
    val_dataset = dataset.get_split_dataset('val')
    test_dataset = dataset.get_split_dataset('test')
    
    # åŠ è½½å¤–éƒ¨æµ‹è¯•é›†
    external_test_dataset = None
    if hasattr(args, 'external_csv_path') and args.external_csv_path:
        print_rank0('\n[1.5/7] Loading External Test Set...')
        external_test_dataset = dataset.load_external_test(
            csv_path=args.external_csv_path,
            h5_dir=args.external_h5_dir
        )
    
    print_rank0(f'\nDataset sizes:')
    print_rank0(f'  Train: {len(train_dataset)} patients')
    print_rank0(f'  Val: {len(val_dataset)} patients')
    print_rank0(f'  Test: {len(test_dataset)} patients')
    if external_test_dataset:
        print_rank0(f'  External Test: {len(external_test_dataset)} patients')
    
    # ========== 2. åˆ›å»ºæ•°æ®åŠ è½½å™¨ (DDP ç‰ˆæœ¬) ==========
    print_rank0('\n[2/7] Creating data loaders...')
    
    train_loader = get_split_loader(
        train_dataset,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        training=True,
        use_ddp=use_ddp,
        world_size=world_size,
        rank=rank
    )
    
    # éªŒè¯/æµ‹è¯•åªåœ¨ä¸»è¿›ç¨‹è¿è¡Œ
    if is_main_process():
        val_loader = get_split_loader(
            val_dataset,
            batch_size=1,
            num_workers=args.num_workers,
            training=False
        )
        
        test_loader = get_split_loader(
            test_dataset,
            batch_size=1,
            num_workers=args.num_workers,
            training=False
        )
        
        if external_test_dataset is not None:
            external_test_loader = get_split_loader(
                external_test_dataset,
                batch_size=1,
                num_workers=args.num_workers,
                training=False
            )
        else:
            external_test_loader = None
    else:
        val_loader = None
        test_loader = None
        external_test_loader = None
    
    print_rank0(f'Train: {len(train_dataset)} samples, {len(train_loader)} batches (batch_size={args.batch_size})')
    if is_main_process():
        print_rank0(f'Val: {len(val_dataset)} samples, {len(val_loader)} batches')
        print_rank0(f'Test: {len(test_dataset)} samples, {len(test_loader)} batches')
        if external_test_loader:
            print_rank0(f'External: {len(external_test_dataset)} samples, {len(external_test_loader)} batches')
    
    # ========== 3. åˆå§‹åŒ–æ¨¡å‹ (DDP ç‰ˆæœ¬) ==========
    print_rank0('\n[3/7] Initializing model...')
    from models.Mamba2MIL import Mamba2MIL
    
    model = Mamba2MIL(
        in_dim=args.in_dim,
        n_classes=args.n_classes,
        dropout=args.dropout,
        act=args.act,
        survival=True,
        layer=args.mamba_layer,
        use_clinical=False
    )
    
    model = model.to(device)
    
    # ğŸ”¥ Step 2: åˆå§‹åŒ– Triton kernels (é¿å… DDP å†²çª)
    print_rank0('Initializing Triton kernels with dummy forward pass...')
    with torch.no_grad():
        dummy_input = torch.randn(1, 100, args.in_dim).to(device)
        try:
            _ = model(dummy_input)
            print_rank0('âœ“ Triton kernels initialized successfully')
        except Exception as e:
            print_rank0(f'âš ï¸  Triton initialization warning: {e}')
            print_rank0('   Continuing anyway...')
    
    # ğŸ”¥ DDP: åŒæ­¥æ‰€æœ‰è¿›ç¨‹
    if use_ddp:
        dist.barrier()
    
    # ğŸ”¥ Step 3: ä½¿ç”¨ DDP åŒ…è£…æ¨¡å‹
    if use_ddp:
        model = DDP(
            model,
            device_ids=[local_rank],
            output_device=local_rank,
            find_unused_parameters=False  # Mamba2 ä¸éœ€è¦
        )
        print_rank0(f'âœ“ Using DDP with {world_size} GPUs')
    
    print_rank0(f'Model: Mamba2MIL')
    
    # ç»Ÿè®¡å‚æ•°
    if isinstance(model, DDP):
        total_params = sum(p.numel() for p in model.module.parameters())
        trainable_params = sum(p.numel() for p in model.module.parameters() if p.requires_grad)
    else:
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print_rank0(f'  Parameters: {total_params:,}')
    print_rank0(f'  Trainable: {trainable_params:,}')
    
    # ========== 4. åˆå§‹åŒ–ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•° ==========
    print_rank0('\n[4/7] Initializing optimizer and loss function...')
    
    if args.optimizer == 'adam':
        optimizer = torch.optim.Adam(
            model.parameters(),
            lr=args.lr,
            weight_decay=args.weight_decay
        )
    elif args.optimizer == 'adamw':
        optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=args.lr,
            weight_decay=args.weight_decay
        )
    
    # åˆå§‹åŒ–æŸå¤±å‡½æ•°
    from utils.survival_loss_function import NLLSurvLoss, CoxSurvLoss, CombinedSurvLoss
    
    if args.loss == 'cox':
        loss_fn = CoxSurvLoss()
        print_rank0(f'Loss: Cox')
    elif args.loss == 'nll':
        loss_fn = NLLSurvLoss(alpha=args.alpha_surv)
        print_rank0(f'Loss: NLL (alpha={args.alpha_surv})')
    elif args.loss == 'combined':
        loss_fn = CombinedSurvLoss(
            main_loss_type='nll',
            alpha=args.alpha_surv,
            ranking_weight=args.ranking_weight,
            ranking_margin=args.ranking_margin
        )
        print_rank0(f'Loss: Combined (NLL + {args.ranking_weight}*Ranking, alpha={args.alpha_surv})')
    
    print_rank0(f'Optimizer: {args.optimizer}, LR: {args.lr}, Weight Decay: {args.weight_decay}')
    
    # ========== 5. è®­ç»ƒå¾ªç¯ ==========
    print_rank0('\n[5/7] Training...')
    
    early_stopping = EarlyStopping(
        warmup=args.warmup,
        patience=args.patience,
        stop_epoch=args.stop_epoch,
        verbose=True
    )
    
    history = {
        'train_loss': [],
        'train_cindex': [],
        'val_loss': [],
        'val_cindex': []
    }
    
    best_val_cindex = 0
    
    for epoch in range(args.max_epochs):
        print_rank0(f'\n{"="*60}')
        print_rank0(f'Epoch {epoch+1}/{args.max_epochs}')
        print_rank0(f'{"="*60}')
        
        # è®­ç»ƒ
        train_loss, train_cindex = train_loop(
            epoch=epoch,
            model=model,
            loader=train_loader,
            optimizer=optimizer,
            loss_fn=loss_fn,
            device=device,
            gc=args.gc,
            use_ddp=use_ddp,
            rank=rank
        )
        
        # ğŸ”¥ DDP: åŒæ­¥æ‰€æœ‰è¿›ç¨‹
        if use_ddp:
            dist.barrier()
        
        # éªŒè¯ (åªåœ¨ä¸»è¿›ç¨‹)
        val_loss, val_cindex = validate(
            epoch=epoch,
            model=model.module if use_ddp else model,
            loader=val_loader,
            loss_fn=loss_fn,
            device=device
        )
        
        # ğŸ”¥ DDP: å¹¿æ’­éªŒè¯ç»“æœåˆ°æ‰€æœ‰è¿›ç¨‹
        if use_ddp:
            val_cindex_tensor = torch.tensor([val_cindex], device=device)
            dist.broadcast(val_cindex_tensor, src=0)
            val_cindex = val_cindex_tensor.item()
        
        # è®°å½•å†å² (åªåœ¨ä¸»è¿›ç¨‹)
        if is_main_process():
            history['train_loss'].append(train_loss)
            history['train_cindex'].append(train_cindex)
            history['val_loss'].append(val_loss)
            history['val_cindex'].append(val_cindex)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹ (åªåœ¨ä¸»è¿›ç¨‹)
        if is_main_process():
            if val_cindex > best_val_cindex:
                best_val_cindex = val_cindex
                if isinstance(model, DDP):
                    torch.save(model.module.state_dict(), os.path.join(fold_dir, 'best_model.pt'))
                else:
                    torch.save(model.state_dict(), os.path.join(fold_dir, 'best_model.pt'))
                print_rank0(f'âœ“ Best model saved (val_cindex={val_cindex:.4f})')
        
        # æ—©åœæ£€æŸ¥
        ckpt_path = os.path.join(fold_dir, 'checkpoint.pt')
        early_stopping(epoch, val_cindex, model, ckpt_name=ckpt_path)
        
        # ğŸ”¥ DDP: å¹¿æ’­æ—©åœä¿¡å·
        if use_ddp:
            early_stop_tensor = torch.tensor([1 if early_stopping.early_stop else 0], device=device)
            dist.broadcast(early_stop_tensor, src=0)
            if early_stop_tensor.item() == 1:
                print_rank0(f'\nEarly stopping at epoch {epoch+1}')
                break
        else:
            if early_stopping.early_stop:
                print_rank0(f'\nEarly stopping at epoch {epoch+1}')
                break
    
    # ä¿å­˜è®­ç»ƒå†å² (åªåœ¨ä¸»è¿›ç¨‹)
    if is_main_process():
        with open(os.path.join(fold_dir, 'history.pkl'), 'wb') as f:
            pickle.dump(history, f)
    
    # ========== 6. æµ‹è¯• (åªåœ¨ä¸»è¿›ç¨‹) ==========
    print_rank0('\n[6/7] Testing...')
    
    if is_main_process():
        # ğŸ”¥ Step 1: è·å–å• GPU æ¨¡å‹
        if use_ddp:
            model_single = model.module
        else:
            model_single = model
        
        # ğŸ”¥ Step 2: åŠ è½½æœ€ä½³æ¨¡å‹
        best_model_path = os.path.join(fold_dir, 'best_model.pt')
        model_single.load_state_dict(torch.load(best_model_path))
        model_single.eval()
        
        print_rank0(f'Loaded best model from: {best_model_path}')
        
        # ğŸ”¥ Step 3: åœ¨éªŒè¯é›†ä¸Šè¯„ä¼° (å• GPU)
        print_rank0('\nEvaluating on validation set...')
        val_loader_test = get_split_loader(
            val_dataset,
            batch_size=1,
            num_workers=args.num_workers,
            training=False,
            use_ddp=False,
            world_size=1,
            rank=0
        )
        
        val_results, val_cindex = test(model_single, val_loader_test, device)
        print_rank0(f'Validation C-Index: {val_cindex:.4f}')
        
        # ğŸ”¥ Step 4: åœ¨å†…éƒ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° (å• GPU)
        print_rank0('\nEvaluating on internal test set...')
        test_loader_test = get_split_loader(
            test_dataset,
            batch_size=1,
            num_workers=args.num_workers,
            training=False,
            use_ddp=False,
            world_size=1,
            rank=0
        )
        
        test_results, test_cindex = test(model_single, test_loader_test, device)
        print_rank0(f'Internal Test C-Index: {test_cindex:.4f}')
        
        # ğŸ”¥ Step 5: åœ¨å¤–éƒ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° (å• GPU)
        external_test_results = None
        external_test_cindex = None
        
        if hasattr(args, 'external_csv_path') and args.external_csv_path:
            print_rank0('\n[7/7] Evaluating on External Test Set...')
            
            # é‡æ–°åŠ è½½å¤–éƒ¨æµ‹è¯•é›†
            from dataset.dataset_h5 import PrognosisDataset
            
            external_test_dataset_reload = PrognosisDataset(
                csv_path=args.external_csv_path,
                h5_dir=args.external_h5_dir,
                label_col=args.label_col,
                use_cache=True,
                print_info=False
            )
            
            external_test_loader_test = get_split_loader(
                external_test_dataset_reload,
                batch_size=1,
                num_workers=args.num_workers,
                training=False,
                use_ddp=False,
                world_size=1,
                rank=0
            )
            
            external_test_results, external_test_cindex = test(
                model_single,
                external_test_loader_test,
                device
            )
            print_rank0(f'External Test C-Index: {external_test_cindex:.4f}')
        
        # ä¿å­˜ç»“æœ
        results = {
            'fold': args.fold,
            'best_val_cindex': best_val_cindex,
            'val_cindex': val_cindex,
            'test_cindex': test_cindex,
            'val_results': val_results,
            'test_results': test_results,
            'history': history
        }
        
        if external_test_results is not None:
            results['external_cindex'] = external_test_cindex
            results['external_test_results'] = external_test_results
        
        with open(os.path.join(fold_dir, 'results.pkl'), 'wb') as f:
            pickle.dump(results, f)
        
        # ä¿å­˜CSV
        val_df = pd.DataFrame([v for v in val_results.values()])
        val_df.to_csv(os.path.join(fold_dir, 'val_results.csv'), index=False)
        
        test_df = pd.DataFrame([v for v in test_results.values()])
        test_df.to_csv(os.path.join(fold_dir, 'test_results.csv'), index=False)
        
        if external_test_results is not None:
            external_df = pd.DataFrame([v for v in external_test_results.values()])
            external_df.to_csv(os.path.join(fold_dir, 'external_test_results.csv'), index=False)
        
        print_rank0('\n' + '='*60)
        print_rank0('Training completed!')
        print_rank0('='*60)
        print_rank0(f'Best Validation C-Index: {best_val_cindex:.4f}')
        print_rank0(f'Final Validation C-Index: {val_cindex:.4f}')
        print_rank0(f'Internal Test C-Index: {test_cindex:.4f}')
        if external_test_cindex is not None:
            print_rank0(f'External Test C-Index: {external_test_cindex:.4f}')
        print_rank0(f'Results saved to: {fold_dir}')
    else:
        results = None
    
    # ğŸ”¥ åŒæ­¥æ‰€æœ‰è¿›ç¨‹
    if use_ddp:
        dist.barrier()
    
    # ğŸ”¥ æ¸…ç† DDP
    cleanup_ddp()
    
    return results


# ===================== K-Foldäº¤å‰éªŒè¯ =====================
def train_k_fold(args):
    """K-Foldäº¤å‰éªŒè¯ - DDP ç‰ˆæœ¬"""
    
    # åªåœ¨ä¸»è¿›ç¨‹è¿è¡Œ K-Fold
    if not is_main_process():
        return None
    
    print_rank0('\n' + '='*60)
    print_rank0(f'K-Fold Cross Validation (K={args.k_fold})')
    print_rank0('='*60)
    
    all_results = []
    
    for fold in range(args.k_fold):
        args.fold = fold
        results = train_survival(args)
        if results is not None:
            all_results.append(results)
    
    # æ±‡æ€»ç»“æœ
    val_cindices = [r['val_cindex'] for r in all_results]
    test_cindices = [r['test_cindex'] for r in all_results]
    
    external_cindices = []
    has_external = False
    for r in all_results:
        if 'external_cindex' in r:
            external_cindices.append(r['external_cindex'])
            has_external = True
    
    print_rank0('\n' + '='*60)
    print_rank0('K-Fold Cross Validation Results')
    print_rank0('='*60)
    
    for fold in range(args.k_fold):
        print_rank0(f'Fold {fold}: Val={val_cindices[fold]:.4f}, Test={test_cindices[fold]:.4f}', end='')
        if has_external:
            print_rank0(f', External={external_cindices[fold]:.4f}')
        else:
            print_rank0()
    
    print_rank0(f'\nMean Val C-Index: {np.mean(val_cindices):.4f} Â± {np.std(val_cindices):.4f}')
    print_rank0(f'Mean Test C-Index: {np.mean(test_cindices):.4f} Â± {np.std(test_cindices):.4f}')
    if has_external:
        print_rank0(f'Mean External C-Index: {np.mean(external_cindices):.4f} Â± {np.std(external_cindices):.4f}')
    
    # ä¿å­˜æ±‡æ€»
    summary = {
        'val_cindices': val_cindices,
        'test_cindices': test_cindices,
        'mean_val_cindex': np.mean(val_cindices),
        'std_val_cindex': np.std(val_cindices),
        'mean_test_cindex': np.mean(test_cindices),
        'std_test_cindex': np.std(test_cindices),
        'all_results': all_results
    }
    
    if has_external:
        summary['external_cindices'] = external_cindices
        summary['mean_external_cindex'] = np.mean(external_cindices)
        summary['std_external_cindex'] = np.std(external_cindices)
    
    with open(os.path.join(args.results_dir, 'summary.pkl'), 'wb') as f:
        pickle.dump(summary, f)
    
    summary_data = {'fold': range(args.k_fold), 'val_cindex': val_cindices, 'test_cindex': test_cindices}
    if has_external:
        summary_data['external_cindex'] = external_cindices
    
    summary_df = pd.DataFrame(summary_data)
    summary_df.to_csv(os.path.join(args.results_dir, 'summary.csv'), index=False)
    
    print_rank0(f'\nSummary saved to: {args.results_dir}')
    
    return summary
