# survival_loss_function.py

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Dict


class CoxSurvLoss(nn.Module):
    """
    Coxæ¯”ä¾‹é£é™©æŸå¤±å‡½æ•°
    
    Cox Proportional Hazards Loss for survival analysis.
    é€‚ç”¨äºç¦»æ•£æ—¶é—´ç”Ÿå­˜åˆ†ææ¨¡å‹ã€‚
    
    Args:
        None
        
    Forward Args:
        hazards: torch.Tensor [batch, n_classes] 
            æ¯ä¸ªæ—¶é—´åŒºé—´çš„é£é™©æ¦‚ç‡
        S: torch.Tensor [batch, n_classes]
            ç”Ÿå­˜å‡½æ•°ï¼ˆæœªä½¿ç”¨ï¼Œä¿æŒæ¥å£ä¸€è‡´æ€§ï¼‰
        Y: torch.Tensor [batch]
            ç¦»æ•£åŒ–çš„ç”Ÿå­˜æ—¶é—´åŒºé—´ç´¢å¼• (0, 1, 2, ..., n_classes-1)
        c: torch.Tensor [batch]
            åˆ å¤±æ ‡è®° (1=åˆ å¤±/censored, 0=äº‹ä»¶å‘ç”Ÿ/event)
            
    Returns:
        loss: torch.Tensor æ ‡é‡æŸå¤±å€¼
        
    Example:
        >>> criterion = CoxSurvLoss()
        >>> hazards = torch.rand(32, 4)  # batch=32, n_classes=4
        >>> S = torch.rand(32, 4)
        >>> Y = torch.randint(0, 4, (32,))
        >>> c = torch.randint(0, 2, (32,))
        >>> loss = criterion(hazards, S, Y, c)
    """
    
    def __init__(self):
        super(CoxSurvLoss, self).__init__()

    def forward(
        self, 
        hazards: torch.Tensor, 
        S: torch.Tensor, 
        Y: torch.Tensor, 
        c: torch.Tensor, 
        **kwargs
    ) -> torch.Tensor:
        batch_size = len(Y)
        Y = Y.view(batch_size, 1)  # [batch, 1]
        c = c.view(batch_size, 1).float()  # [batch, 1]
        
        # åˆ›å»º one-hot ç¼–ç 
        Y_one_hot = torch.zeros_like(hazards).scatter_(1, Y, 1)
        
        # è®¡ç®—å¯¹æ•°é£é™©ï¼ˆæ·»åŠ å°å€¼é¿å…log(0)ï¼‰
        hazards_log = torch.log(torch.clamp(hazards, min=1e-7))
        
        # Cox loss: åªå¯¹æœªåˆ å¤±æ ·æœ¬è®¡ç®—åˆ°è¯¥æ—¶é—´ç‚¹çš„ç´¯ç§¯å¯¹æ•°é£é™©
        # åˆ å¤±æ ·æœ¬ä¸è´¡çŒ®æŸå¤±ï¼ˆå› ä¸ºæˆ‘ä»¬ä¸çŸ¥é“çœŸå®äº‹ä»¶æ—¶é—´ï¼‰
        loss = -(1 - c) * (Y_one_hot * hazards_log).sum(dim=1)
        loss = loss.mean()
        
        return loss


class NLLSurvLoss(nn.Module):
    """
    è´Ÿå¯¹æ•°ä¼¼ç„¶ç”Ÿå­˜æŸå¤±å‡½æ•°
    
    Negative Log-Likelihood Survival Loss for discrete-time survival analysis.
    
    è¯¥æŸå¤±å‡½æ•°åŸºäºç¦»æ•£æ—¶é—´ç”Ÿå­˜åˆ†æï¼Œå°†è¿ç»­æ—¶é—´ç¦»æ•£åŒ–ä¸ºkä¸ªåŒºé—´ï¼š
    T_cont âˆˆ {[0, a_1), [a_1, a_2), ..., [a_(k-1), âˆ)}
    
    æ ¸å¿ƒæ¦‚å¿µï¼š
    - hazards(t): P(Y=t | Yâ‰¥t, X) - åœ¨å­˜æ´»åˆ°æ—¶é—´tçš„æ¡ä»¶ä¸‹ï¼Œåœ¨æ—¶é—´tæ­»äº¡çš„æ¦‚ç‡
    - S(t): P(Y > t | X) - å­˜æ´»è¶…è¿‡æ—¶é—´tçš„æ¦‚ç‡
    - S(t) = âˆ(1 - hazards(i)) for i=0 to t
    
    Args:
        alpha: float, default=0.0
            å¹³è¡¡åˆ å¤±å’Œæœªåˆ å¤±æ ·æœ¬çš„æƒé‡å‚æ•°
            - alpha=0: åˆ å¤±å’Œæœªåˆ å¤±æ ·æœ¬æƒé‡ç›¸åŒ
            - alpha>0: ç»™æœªåˆ å¤±æ ·æœ¬æ›´å¤šæƒé‡
            - alpha=1: åªè€ƒè™‘æœªåˆ å¤±æ ·æœ¬
            
    Forward Args:
        hazards: torch.Tensor [batch, n_classes]
            æ¯ä¸ªæ—¶é—´åŒºé—´çš„é£é™©æ¦‚ç‡
        S: torch.Tensor [batch, n_classes]
            ç”Ÿå­˜å‡½æ•°ï¼ŒS(t) = P(Y > t | X)
        Y: torch.Tensor [batch]
            ç¦»æ•£åŒ–çš„ç”Ÿå­˜æ—¶é—´åŒºé—´ç´¢å¼• (0, 1, 2, ..., n_classes-1)
        c: torch.Tensor [batch]
            åˆ å¤±æ ‡è®° (1=åˆ å¤±/censored, 0=äº‹ä»¶å‘ç”Ÿ/event)
        alpha: float, optional
            å¦‚æœæä¾›ï¼Œè¦†ç›–åˆå§‹åŒ–æ—¶çš„alphaå€¼
            
    Returns:
        loss: torch.Tensor æ ‡é‡æŸå¤±å€¼
        
    Loss Formulation:
        å¯¹äºæœªåˆ å¤±æ ·æœ¬ (c=0):
            L = -log(P(Y=y)) = -log(S(y-1) * h(y))
            = -log(S(y-1)) - log(h(y))
            
        å¯¹äºåˆ å¤±æ ·æœ¬ (c=1):
            L = -log(P(Y>y)) = -log(S(y))
            
        æ€»æŸå¤±:
            L_total = (1-Î±) * (L_censored + L_uncensored) + Î± * L_uncensored
            
    Example:
        >>> criterion = NLLSurvLoss(alpha=0.15)
        >>> hazards = torch.rand(32, 4)
        >>> S = torch.cumprod(1 - hazards, dim=1)  # è®¡ç®—ç”Ÿå­˜å‡½æ•°
        >>> Y = torch.randint(0, 4, (32,))
        >>> c = torch.randint(0, 2, (32,))
        >>> loss = criterion(hazards, S, Y, c)
    """
    
    def __init__(self, alpha: float = 0.0):
        super(NLLSurvLoss, self).__init__()
        self.alpha = alpha

    def forward(
        self, 
        hazards: torch.Tensor, 
        S: torch.Tensor, 
        Y: torch.Tensor, 
        c: torch.Tensor, 
        alpha: Optional[float] = None,
        **kwargs
    ) -> torch.Tensor:
        if alpha is None:
            alpha = self.alpha
        
        batch_size = len(Y)
        Y = Y.view(batch_size, 1)  # [batch, 1]
        c = c.view(batch_size, 1).float()  # [batch, 1]
        
        # Padding: S(-1) = 1 (æ‰€æœ‰æ‚£è€…åœ¨æ—¶é—´-1éƒ½å­˜æ´»)
        # S_padded[0] = S(-1) = 1
        # S_padded[1] = S(0)
        # S_padded[2] = S(1), ...
        S_padded = torch.cat([torch.ones_like(c), S], dim=1)
        
        # è·å–å¯¹åº”æ—¶é—´ç‚¹çš„æ¦‚ç‡
        s_prev = torch.gather(S_padded, dim=1, index=Y).clamp(min=1e-7)      # S(Y-1): å­˜æ´»åˆ°Y-1çš„æ¦‚ç‡
        h = torch.gather(hazards, dim=1, index=Y).clamp(min=1e-7)            # h(Y): åœ¨Yæ—¶åˆ»æ­»äº¡çš„æ¦‚ç‡
        s_now = torch.gather(S_padded, dim=1, index=Y+1).clamp(min=1e-7)     # S(Y): å­˜æ´»è¶…è¿‡Yçš„æ¦‚ç‡
        
        # è®¡ç®—è´Ÿå¯¹æ•°ä¼¼ç„¶
        # æœªåˆ å¤±æ ·æœ¬: -log(P(Y=y)) = -log(S(y-1) * h(y)) = -log(S(y-1)) - log(h(y))
        uncensored_loss = -(1 - c) * (torch.log(s_prev) + torch.log(h))
        
        # åˆ å¤±æ ·æœ¬: -log(P(Y>y)) = -log(S(y))
        censored_loss = -c * torch.log(s_now)
        
        # ç»„åˆæŸå¤±ï¼ˆå¯é€‰åŠ æƒï¼‰
        if alpha == 0:
            # æ ‡å‡†NLLæŸå¤±
            loss = uncensored_loss + censored_loss
        else:
            # åŠ æƒæŸå¤±ï¼šç»™æœªåˆ å¤±æ ·æœ¬æ›´å¤šæƒé‡
            loss = (1 - alpha) * (uncensored_loss + censored_loss) + alpha * uncensored_loss
        
        loss = loss.mean()
        
        return loss


class RankingLoss(nn.Module):
    """
    æ’åºæŸå¤±å‡½æ•°ï¼ˆå¯é€‰ï¼‰
    
    Ranking Loss for survival analysis, ensures that patients with 
    earlier event times have higher risk scores.
    
    Args:
        margin: float, default=0.0
            æ’åºæŸå¤±çš„è¾¹ç•Œå€¼
            
    Forward Args:
        hazards: torch.Tensor [batch, n_classes]
        S: torch.Tensor [batch, n_classes]
        Y: torch.Tensor [batch]
        c: torch.Tensor [batch]
        
    Returns:
        loss: torch.Tensor
    """
    
    def __init__(self, margin: float = 0.0):
        super(RankingLoss, self).__init__()
        self.margin = margin
    
    def forward(
        self,
        hazards: torch.Tensor,
        S: torch.Tensor,
        Y: torch.Tensor,
        c: torch.Tensor,
        **kwargs
    ) -> torch.Tensor:
        batch_size = len(Y)
        
        # è®¡ç®—é£é™©åˆ†æ•°ï¼ˆå¯ä»¥ä½¿ç”¨ç´¯ç§¯é£é™©æˆ–å…¶ä»–åº¦é‡ï¼‰
        risk_scores = hazards.sum(dim=1)  # [batch]
        
        # æ„å»ºæˆå¯¹æ¯”è¾ƒ
        loss = torch.tensor(0.0, device=hazards.device, dtype=hazards.dtype)  # ğŸ”¥ ä¿®å¤: åˆå§‹åŒ–ä¸ºtensor
        count = 0
        
        for i in range(batch_size):
            if c[i] == 0:  # åªè€ƒè™‘æœªåˆ å¤±æ ·æœ¬
                for j in range(batch_size):
                    if Y[j] > Y[i]:  # jçš„äº‹ä»¶æ—¶é—´æ™šäºi
                        # iåº”è¯¥æœ‰æ›´é«˜çš„é£é™©åˆ†æ•°
                        loss += torch.relu(self.margin + risk_scores[j] - risk_scores[i])
                        count += 1
        
        if count > 0:
            loss = loss / count
        
        return loss


class CombinedSurvLoss(nn.Module):
    """
    ç»„åˆç”Ÿå­˜æŸå¤± = ä¸»æŸå¤±(NLL/Cox) + Î» * Ranking Loss
    
    Args:
        main_loss_type: str, ä¸»æŸå¤±ç±»å‹ ('nll' or 'cox')
        alpha: float, NLLæŸå¤±çš„alphaå‚æ•° (ä»…å½“main_loss_type='nll'æ—¶ä½¿ç”¨)
        ranking_weight: float, ranking lossçš„æƒé‡ç³»æ•° Î»
        ranking_margin: float, ranking lossçš„è¾¹ç•Œå€¼
    """
    def __init__(
        self, 
        main_loss_type: str = 'nll',
        alpha: float = 0.0,
        ranking_weight: float = 0.1,
        ranking_margin: float = 0.0
    ):
        super(CombinedSurvLoss, self).__init__()
        
        # ä¸»æŸå¤±
        if main_loss_type.lower() == 'nll':
            self.main_loss = NLLSurvLoss(alpha=alpha)
        elif main_loss_type.lower() == 'cox':
            self.main_loss = CoxSurvLoss()
        else:
            raise ValueError(f"Unknown main_loss_type: {main_loss_type}")
        
        # RankingæŸå¤±
        self.ranking_loss = RankingLoss(margin=ranking_margin)
        self.ranking_weight = ranking_weight
        self.main_loss_type = main_loss_type.lower()
    
    def forward(
        self,
        hazards: torch.Tensor,
        S: torch.Tensor,
        Y: torch.Tensor,
        c: torch.Tensor,
        **kwargs
    ) -> torch.Tensor:
        # è®¡ç®—ä¸»æŸå¤±
        main_loss_value = self.main_loss(hazards, S, Y, c, **kwargs)
        
        # è®¡ç®—rankingæŸå¤±
        ranking_loss_value = self.ranking_loss(hazards, S, Y, c)
        
        # ç»„åˆ
        total_loss = main_loss_value + self.ranking_weight * ranking_loss_value
        
        return total_loss
    
    def get_loss_components(
        self,
        hazards: torch.Tensor,
        S: torch.Tensor,
        Y: torch.Tensor,
        c: torch.Tensor,
        **kwargs
    ) -> Dict[str, float]:
        """
        è¿”å›å„ä¸ªæŸå¤±åˆ†é‡(ç”¨äºç›‘æ§)
        
        ğŸ”¥ ä¿®å¤: ç¡®ä¿è¿”å›floatç±»å‹
        """
        # ğŸ”¥ ä¸ä½¿ç”¨no_gradï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦è®¡ç®—æ¢¯åº¦
        # ä½†å¯ä»¥detachåå†è½¬æ¢ä¸ºfloat
        main_loss_value = self.main_loss(hazards, S, Y, c, **kwargs)
        ranking_loss_value = self.ranking_loss(hazards, S, Y, c)
        
        # ğŸ”¥ è½¬æ¢ä¸ºfloat
        return {
            'main_loss': main_loss_value.detach().item(),
            'ranking_loss': ranking_loss_value.detach().item(),
            'total_loss': (main_loss_value + self.ranking_weight * ranking_loss_value).detach().item()
        }


# ===================== æŸå¤±å‡½æ•°å·¥å‚ =====================
class SurvivalLossFactory:
    """ç”Ÿå­˜åˆ†ææŸå¤±å‡½æ•°å·¥å‚"""
    
    AVAILABLE_LOSSES = ['nll', 'cox', 'ranking', 'combined']
    
    @staticmethod
    def get_loss(
        loss_type: str = 'nll',
        **kwargs
    ) -> nn.Module:
        """
        åˆ›å»ºæŸå¤±å‡½æ•°
        
        Args:
            loss_type: æŸå¤±ç±»å‹ ('nll', 'cox', 'ranking', 'combined')
            **kwargs: æŸå¤±å‡½æ•°å‚æ•°
            
        Returns:
            criterion: nn.Module
        """
        loss_type = loss_type.lower()
        
        if loss_type == 'nll':
            alpha = kwargs.get('alpha', 0.0)
            return NLLSurvLoss(alpha=alpha)
        
        elif loss_type == 'cox':
            return CoxSurvLoss()
        
        elif loss_type == 'ranking':
            margin = kwargs.get('margin', 0.0)
            return RankingLoss(margin=margin)
        
        elif loss_type == 'combined':
            # ç»„åˆæŸå¤±
            main_loss_type = kwargs.get('main_loss_type', 'nll')
            alpha = kwargs.get('alpha', 0.0)
            ranking_weight = kwargs.get('ranking_weight', 0.1)
            ranking_margin = kwargs.get('ranking_margin', 0.0)
            return CombinedSurvLoss(
                main_loss_type=main_loss_type,
                alpha=alpha,
                ranking_weight=ranking_weight,
                ranking_margin=ranking_margin
            )
        
        else:
            raise ValueError(
                f"Unknown loss type: {loss_type}. "
                f"Available losses: {SurvivalLossFactory.AVAILABLE_LOSSES}"
            )
    
    @staticmethod
    def list_available_losses():
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æŸå¤±å‡½æ•°"""
        return SurvivalLossFactory.AVAILABLE_LOSSES


# ===================== ä¾¿æ·å‡½æ•° =====================
def create_survival_loss(loss_type: str = 'nll', **kwargs) -> nn.Module:
    """
    åˆ›å»ºç”Ÿå­˜åˆ†ææŸå¤±å‡½æ•°çš„ä¾¿æ·å‡½æ•°
    
    Args:
        loss_type: str, æŸå¤±å‡½æ•°ç±»å‹ ('nll', 'cox', 'ranking', 'combined')
        **kwargs: æŸå¤±å‡½æ•°å‚æ•°
        
    Returns:
        criterion: nn.Module
        
    Example:
        >>> # NLLæŸå¤±
        >>> criterion = create_survival_loss('nll', alpha=0.15)
        >>> loss = criterion(hazards, S, Y, c)
        
        >>> # ç»„åˆæŸå¤±
        >>> criterion = create_survival_loss(
        ...     'combined',
        ...     main_loss_type='nll',
        ...     alpha=0.15,
        ...     ranking_weight=0.1,
        ...     ranking_margin=0.0
        ... )
        >>> loss = criterion(hazards, S, Y, c)
    """
    return SurvivalLossFactory.get_loss(loss_type, **kwargs)


# ===================== æµ‹è¯•ä»£ç  =====================
if __name__ == '__main__':
    print("=" * 60)
    print("æµ‹è¯•ç”Ÿå­˜åˆ†ææŸå¤±å‡½æ•°")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    batch_size = 8
    n_classes = 4
    
    torch.manual_seed(42)
    hazards = torch.rand(batch_size, n_classes)
    hazards = F.softmax(hazards, dim=1)  # å½’ä¸€åŒ–
    S = torch.cumprod(1 - hazards, dim=1)  # è®¡ç®—ç”Ÿå­˜å‡½æ•°
    Y = torch.randint(0, n_classes, (batch_size,))
    c = torch.randint(0, 2, (batch_size,))
    
    print(f"\nè¾“å…¥æ•°æ®:")
    print(f"  hazards shape: {hazards.shape}")
    print(f"  S shape: {S.shape}")
    print(f"  Y: {Y.tolist()}")
    print(f"  c (censoring): {c.tolist()}")
    
    # æµ‹è¯• NLL Loss
    print("\n" + "-" * 60)
    print("æµ‹è¯• NLL Loss")
    print("-" * 60)
    nll_criterion = create_survival_loss('nll', alpha=0.15)
    nll_loss = nll_criterion(hazards, S, Y, c)
    print(f"NLL Loss: {nll_loss.item():.4f}")
    print(f"  Type: {type(nll_loss)}")
    print(f"  Requires grad: {nll_loss.requires_grad}")
    
    # æµ‹è¯• Cox Loss
    print("\n" + "-" * 60)
    print("æµ‹è¯• Cox Loss")
    print("-" * 60)
    cox_criterion = create_survival_loss('cox')
    cox_loss = cox_criterion(hazards, S, Y, c)
    print(f"Cox Loss: {cox_loss.item():.4f}")
    print(f"  Type: {type(cox_loss)}")
    print(f"  Requires grad: {cox_loss.requires_grad}")
    
    # æµ‹è¯• Ranking Loss
    print("\n" + "-" * 60)
    print("æµ‹è¯• Ranking Loss")
    print("-" * 60)
    ranking_criterion = create_survival_loss('ranking', margin=0.1)
    ranking_loss = ranking_criterion(hazards, S, Y, c)
    print(f"Ranking Loss: {ranking_loss.item():.4f}")
    print(f"  Type: {type(ranking_loss)}")
    print(f"  Requires grad: {ranking_loss.requires_grad}")
    
    # ğŸ”¥ æµ‹è¯• Combined Loss
    print("\n" + "-" * 60)
    print("æµ‹è¯• Combined Loss")
    print("-" * 60)
    combined_criterion = create_survival_loss(
        'combined',
        main_loss_type='nll',
        alpha=0.15,
        ranking_weight=0.1,
        ranking_margin=0.1
    )
    combined_loss = combined_criterion(hazards, S, Y, c)
    print(f"Combined Loss: {combined_loss.item():.4f}")
    print(f"  Type: {type(combined_loss)}")
    print(f"  Requires grad: {combined_loss.requires_grad}")
    
    # ğŸ”¥ æµ‹è¯• get_loss_components
    print("\n  Loss Components:")
    components = combined_criterion.get_loss_components(hazards, S, Y, c)
    for key, value in components.items():
        print(f"    {key}: {value:.4f} (type: {type(value).__name__})")
    
    # æµ‹è¯•åå‘ä¼ æ’­
    print("\n" + "-" * 60)
    print("æµ‹è¯•åå‘ä¼ æ’­")
    print("-" * 60)
    
    # åˆ›å»ºéœ€è¦æ¢¯åº¦çš„hazards
    hazards_grad = torch.rand(batch_size, n_classes, requires_grad=True)
    hazards_grad = F.softmax(hazards_grad, dim=1)
    S_grad = torch.cumprod(1 - hazards_grad, dim=1)
    
    # è®¡ç®—æŸå¤±
    loss = combined_criterion(hazards_grad, S_grad, Y, c)
    print(f"Loss: {loss.item():.4f}")
    
    # åå‘ä¼ æ’­
    loss.backward()
    print(f"âœ“ Backward pass successful")
    print(f"  Gradient shape: {hazards_grad.grad.shape}")
    print(f"  Gradient mean: {hazards_grad.grad.mean().item():.6f}")
    print(f"  Gradient std: {hazards_grad.grad.std().item():.6f}")
    
    # åˆ—å‡ºæ‰€æœ‰å¯ç”¨æŸå¤±
    print("\n" + "-" * 60)
    print("å¯ç”¨çš„æŸå¤±å‡½æ•°:")
    print("-" * 60)
    for loss_name in SurvivalLossFactory.list_available_losses():
        print(f"  - {loss_name}")
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆï¼âœ…")
    print("=" * 60)
