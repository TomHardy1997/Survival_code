"""
ç”Ÿå­˜åˆ†æè®­ç»ƒä¸»è„šæœ¬ - æŠ—è¿‡æ‹Ÿåˆå¢å¼ºç‰ˆ
"""
import os
import sys
import argparse
import torch
import numpy as np
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.core_utils2 import train_survival, train_k_fold


def main():
    parser = argparse.ArgumentParser(description='Survival Analysis Training - Enhanced Version')
    
    # ========== æ•°æ®å‚æ•° ==========
    data_group = parser.add_argument_group('Data Parameters')
    data_group.add_argument('--csv_path', type=str, required=True,
                           help='è®­ç»ƒé›†CSVæ–‡ä»¶è·¯å¾„')
    data_group.add_argument('--h5_base_dir', type=str, required=True,
                           help='H5ç‰¹å¾æ–‡ä»¶åŸºç¡€ç›®å½•')
    data_group.add_argument('--feature_models', type=str, nargs='+', 
                           default=['uni_v1'],
                           help='ç‰¹å¾æå–æ¨¡å‹åˆ—è¡¨ (æ”¯æŒå¤šæ¨¡å‹èåˆ)')
    data_group.add_argument('--label_col', type=str, default='disc_label',
                           help='æ ‡ç­¾åˆ—å')
    
    # ========== å¤–éƒ¨æµ‹è¯•é›†å‚æ•° ==========
    external_group = parser.add_argument_group('External Test Set Parameters')
    external_group.add_argument('--external_csv_path', type=str, default=None,
                               help='å¤–éƒ¨æµ‹è¯•é›†CSVæ–‡ä»¶è·¯å¾„ (å¯é€‰)')
    external_group.add_argument('--external_h5_base_dir', type=str, default=None,
                               help='å¤–éƒ¨æµ‹è¯•é›†H5ç‰¹å¾æ–‡ä»¶åŸºç¡€ç›®å½• (å¯é€‰)')
    
    # ========== æ¨¡å‹å‚æ•° ==========
    model_group = parser.add_argument_group('Model Parameters')
    model_group.add_argument('--model_version', type=str, default='standard',
                            choices=['standard', 'lite'],
                            help='æ¨¡å‹ç‰ˆæœ¬: standard(æ ‡å‡†) æˆ– lite(è½»é‡çº§)')
    model_group.add_argument('--in_dim', type=int, default=1024,
                            help='è¾“å…¥ç‰¹å¾ç»´åº¦')
    model_group.add_argument('--n_classes', type=int, default=4,
                            help='ç”Ÿå­˜æ—¶é—´åŒºé—´æ•°é‡')
    model_group.add_argument('--dropout', type=float, default=0.4,
                            help='Dropoutæ¯”ç‡ (æ¨è0.3-0.5)')
    model_group.add_argument('--drop_path_rate', type=float, default=0.1,
                            help='Stochastic Depthæ¯”ç‡ (ä»…standardç‰ˆæœ¬)')
    model_group.add_argument('--feature_dropout', type=float, default=0.1,
                            help='ç‰¹å¾å±‚Dropoutæ¯”ç‡ (ä»…standardç‰ˆæœ¬)')
    model_group.add_argument('--act', type=str, default='gelu',
                            choices=['relu', 'gelu'],
                            help='æ¿€æ´»å‡½æ•°')
    model_group.add_argument('--mamba_layer', type=int, default=2,
                            help='Mambaå±‚æ•° (1-3, è¿‡æ‹Ÿåˆæ—¶å»ºè®®ç”¨1)')
    
    # ========== è®­ç»ƒå‚æ•° ==========
    train_group = parser.add_argument_group('Training Parameters')
    train_group.add_argument('--batch_size', type=int, default=4,
                            help='æ‰¹å¤§å° (DDPæ—¶ä¼šè‡ªåŠ¨åˆ†é…åˆ°å„GPU)')
    train_group.add_argument('--max_epochs', type=int, default=100,
                            help='æœ€å¤§è®­ç»ƒè½®æ•°')
    train_group.add_argument('--lr', type=float, default=5e-5,
                            help='å­¦ä¹ ç‡ (æ¨è1e-5åˆ°1e-4)')
    train_group.add_argument('--weight_decay', type=float, default=1e-3,
                            help='æƒé‡è¡°å‡/L2æ­£åˆ™åŒ– (æ¨è1e-4åˆ°1e-2)')
    train_group.add_argument('--optimizer', type=str, default='adamw',
                            choices=['adam', 'adamw'],
                            help='ä¼˜åŒ–å™¨ (æ¨èadamw)')
    train_group.add_argument('--loss', type=str, default='combined',
                            choices=['cox', 'nll', 'combined'],
                            help='æŸå¤±å‡½æ•°ç±»å‹')
    train_group.add_argument('--alpha_surv', type=float, default=0.0,
                            help='NLLæŸå¤±çš„alphaå‚æ•°')
    train_group.add_argument('--gc', type=int, default=1,
                            help='æ¢¯åº¦ç´¯ç§¯æ­¥æ•°')
    
    # ========== ğŸ”¥ æ–°å¢: æ­£åˆ™åŒ–å‚æ•° ==========
    reg_group = parser.add_argument_group('Regularization Parameters')
    reg_group.add_argument('--max_grad_norm', type=float, default=1.0,
                          help='æ¢¯åº¦è£å‰ªé˜ˆå€¼ (é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸)')
    reg_group.add_argument('--feature_drop_rate', type=float, default=0.1,
                          help='è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒpatchçš„æ¯”ç‡ (æ•°æ®å¢å¼º)')
    reg_group.add_argument('--label_smoothing', type=float, default=0.0,
                          help='æ ‡ç­¾å¹³æ»‘ç³»æ•° (0-0.1)')
    
    # ========== ğŸ”¥ æ–°å¢: å­¦ä¹ ç‡è°ƒåº¦å‚æ•° ==========
    scheduler_group = parser.add_argument_group('Learning Rate Scheduler Parameters')
    scheduler_group.add_argument('--scheduler', type=str, default='cosine',
                                choices=['none', 'cosine', 'step', 'plateau'],
                                help='å­¦ä¹ ç‡è°ƒåº¦å™¨ç±»å‹')
    scheduler_group.add_argument('--lr_step_size', type=int, default=30,
                                help='StepLRçš„æ­¥é•¿ (ä»…scheduler=stepæ—¶ä½¿ç”¨)')
    scheduler_group.add_argument('--lr_gamma', type=float, default=0.5,
                                help='StepLRçš„è¡°å‡ç‡ (ä»…scheduler=stepæ—¶ä½¿ç”¨)')
    scheduler_group.add_argument('--warmup_epochs', type=int, default=0,
                                help='å­¦ä¹ ç‡é¢„çƒ­è½®æ•° (0è¡¨ç¤ºä¸ä½¿ç”¨)')
    
    # ========== Ranking Losså‚æ•° ==========
    ranking_group = parser.add_argument_group('Ranking Loss Parameters')
    ranking_group.add_argument('--ranking_weight', type=float, default=0.1,
                              help='Ranking lossæƒé‡ (ä»…loss=combinedæ—¶ä½¿ç”¨)')
    ranking_group.add_argument('--ranking_margin', type=float, default=0.0,
                              help='Ranking lossè¾¹ç•Œå€¼ (ä»…loss=combinedæ—¶ä½¿ç”¨)')
    
    # ========== æ—©åœå‚æ•° ==========
    early_stop_group = parser.add_argument_group('Early Stopping Parameters')
    early_stop_group.add_argument('--warmup', type=int, default=5,
                                  help='æ—©åœé¢„çƒ­è½®æ•°')
    early_stop_group.add_argument('--patience', type=int, default=15,
                                  help='æ—©åœè€å¿ƒå€¼')
    early_stop_group.add_argument('--stop_epoch', type=int, default=20,
                                  help='æ—©åœæœ€å°è½®æ•°')
    early_stop_group.add_argument('--early_stop_delta', type=float, default=0.0001,
                                  help='æ—©åœæœ€å°æ”¹è¿›é˜ˆå€¼')
    early_stop_group.add_argument('--save_all_checkpoints', action='store_true',
                                  help='æ˜¯å¦ä¿å­˜æ‰€æœ‰epochçš„æ£€æŸ¥ç‚¹')
    
    # ========== K-Foldå‚æ•° ==========
    kfold_group = parser.add_argument_group('K-Fold Parameters')
    kfold_group.add_argument('--k_fold', type=int, default=5,
                            help='K-FoldæŠ˜æ•°')
    kfold_group.add_argument('--fold', type=int, default=None,
                            help='æŒ‡å®šè®­ç»ƒæŸä¸ªfold (Noneè¡¨ç¤ºè®­ç»ƒæ‰€æœ‰fold)')
    kfold_group.add_argument('--val_ratio', type=float, default=0.15,
                            help='éªŒè¯é›†æ¯”ä¾‹')
    kfold_group.add_argument('--test_ratio', type=float, default=0.15,
                            help='æµ‹è¯•é›†æ¯”ä¾‹')
    
    # ========== ğŸ”¥ æ–°å¢: DDPå‚æ•° ==========
    ddp_group = parser.add_argument_group('Distributed Training Parameters')
    ddp_group.add_argument('--local_rank', type=int, default=-1,
                          help='DDP local rank (è‡ªåŠ¨è®¾ç½®)')
    
    # ========== å…¶ä»–å‚æ•° ==========
    misc_group = parser.add_argument_group('Miscellaneous Parameters')
    misc_group.add_argument('--results_dir', type=str, default='./results',
                           help='ç»“æœä¿å­˜ç›®å½•')
    misc_group.add_argument('--exp_name', type=str, default=None,
                           help='å®éªŒåç§° (ç”¨äºåŒºåˆ†ä¸åŒå®éªŒ)')
    misc_group.add_argument('--num_workers', type=int, default=4,
                           help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    misc_group.add_argument('--seed', type=int, default=42,
                           help='éšæœºç§å­')
    misc_group.add_argument('--resume', type=str, default=None,
                           help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    misc_group.add_argument('--eval_only', action='store_true',
                           help='ä»…è¯„ä¼°æ¨¡å¼ (éœ€è¦--resume)')
    
    # ========== è§£æå‚æ•° ==========
    args = parser.parse_args()
    
    # ========== ğŸ”¥ è‡ªåŠ¨ç”Ÿæˆå®éªŒåç§° ==========
    if args.exp_name is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        args.exp_name = f'{args.model_version}_layer{args.mamba_layer}_drop{args.dropout}_{timestamp}'
    
    # æ›´æ–°ç»“æœç›®å½•
    args.results_dir = os.path.join(args.results_dir, args.exp_name)
    
    # ========== éªŒè¯å‚æ•° ==========
    # å¤–éƒ¨æµ‹è¯•é›†
    if args.external_csv_path and not args.external_h5_base_dir:
        parser.error('--external_h5_base_dir is required when --external_csv_path is provided')
    if args.external_h5_base_dir and not args.external_csv_path:
        parser.error('--external_csv_path is required when --external_h5_base_dir is provided')
    
    # æŸå¤±å‡½æ•°
    if args.loss == 'combined':
        if args.ranking_weight <= 0:
            print(f'âš ï¸  Warning: loss=combined but ranking_weight={args.ranking_weight}, setting to 0.1')
            args.ranking_weight = 0.1
    
    # æ¨¡å‹ç‰ˆæœ¬
    if args.model_version == 'lite':
        if args.mamba_layer > 1:
            print(f'âš ï¸  Warning: lite version with mamba_layer={args.mamba_layer}, setting to 1')
            args.mamba_layer = 1
    
    # è¯„ä¼°æ¨¡å¼
    if args.eval_only and not args.resume:
        parser.error('--resume is required when --eval_only is set')
    
    # ========== è®¾ç½®éšæœºç§å­ ==========
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    
    # ========== åˆ›å»ºç»“æœç›®å½• ==========
    os.makedirs(args.results_dir, exist_ok=True)
    
    # ========== ä¿å­˜é…ç½® (JSON + TXT) ==========
    # JSONæ ¼å¼ (æ–¹ä¾¿ç¨‹åºè¯»å–)
    config_json_path = os.path.join(args.results_dir, 'config.json')
    with open(config_json_path, 'w') as f:
        json.dump(vars(args), f, indent=4, sort_keys=True)
    
    # TXTæ ¼å¼ (æ–¹ä¾¿äººç±»é˜…è¯»)
    config_txt_path = os.path.join(args.results_dir, 'config.txt')
    with open(config_txt_path, 'w') as f:
        f.write('='*80 + '\n')
        f.write(f'Experiment: {args.exp_name}\n')
        f.write(f'Time: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n')
        f.write('='*80 + '\n\n')
        
        # æŒ‰ç»„æ‰“å°
        groups = {
            'Data': ['csv_path', 'h5_base_dir', 'feature_models', 'label_col'],
            'External Test': ['external_csv_path', 'external_h5_base_dir'],
            'Model': ['model_version', 'in_dim', 'n_classes', 'dropout', 
                     'drop_path_rate', 'feature_dropout', 'act', 'mamba_layer'],
            'Training': ['batch_size', 'max_epochs', 'lr', 'weight_decay', 
                        'optimizer', 'loss', 'alpha_surv', 'gc'],
            'Regularization': ['max_grad_norm', 'feature_drop_rate', 'label_smoothing'],
            'Scheduler': ['scheduler', 'lr_step_size', 'lr_gamma', 'warmup_epochs'],
            'Ranking Loss': ['ranking_weight', 'ranking_margin'],
            'Early Stopping': ['warmup', 'patience', 'stop_epoch', 
                              'early_stop_delta', 'save_all_checkpoints'],
            'K-Fold': ['k_fold', 'fold', 'val_ratio', 'test_ratio'],
            'Misc': ['results_dir', 'exp_name', 'num_workers', 'seed', 
                    'resume', 'eval_only']
        }
        
        for group_name, keys in groups.items():
            f.write(f'\n[{group_name}]\n')
            f.write('-' * 80 + '\n')
            for key in keys:
                if key in vars(args):
                    value = getattr(args, key)
                    f.write(f'{key:25s}: {value}\n')
        
        f.write('\n' + '='*80 + '\n')
    
    # ========== æ‰“å°é…ç½® ==========
    print('\n' + '='*80)
    print(f'Experiment: {args.exp_name}')
    print(f'Time: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
    print('='*80)
    
    # æ‰“å°å…³é”®å‚æ•°
    print('\nğŸ”§ Key Parameters:')
    print(f'  Model: {args.model_version} (layer={args.mamba_layer}, dropout={args.dropout})')
    print(f'  Training: lr={args.lr}, wd={args.weight_decay}, batch={args.batch_size}')
    print(f'  Loss: {args.loss}', end='')
    if args.loss == 'combined':
        print(f' (ranking_weight={args.ranking_weight})')
    else:
        print()
    print(f'  Regularization: grad_clip={args.max_grad_norm}, feature_drop={args.feature_drop_rate}')
    print(f'  Scheduler: {args.scheduler}')
    print(f'  Early Stop: patience={args.patience}, delta={args.early_stop_delta}')
    
    # ========== æ‰“å°è®¾å¤‡ä¿¡æ¯ ==========
    print('\nğŸ’» Device Information:')
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f'  Device: {device}')
    if torch.cuda.is_available():
        print(f'  GPU Count: {torch.cuda.device_count()}')
        for i in range(torch.cuda.device_count()):
            print(f'  GPU {i}: {torch.cuda.get_device_name(i)}')
            print(f'    Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB')
    
    # æ£€æŸ¥DDP
    if 'WORLD_SIZE' in os.environ:
        world_size = int(os.environ['WORLD_SIZE'])
        rank = int(os.environ['RANK'])
        print(f'\nğŸš€ Distributed Training:')
        print(f'  World Size: {world_size}')
        print(f'  Rank: {rank}')
    
    print('='*80 + '\n')
    
    # ========== ğŸ”¥ æ¨èé…ç½®æ£€æŸ¥ ==========
    warnings = []
    
    # æ£€æŸ¥è¿‡æ‹Ÿåˆé£é™©
    if args.dropout < 0.3:
        warnings.append(f'âš ï¸  dropout={args.dropout} å¯èƒ½å¤ªå°ï¼Œæ¨è0.3-0.5')
    
    if args.weight_decay < 1e-4:
        warnings.append(f'âš ï¸  weight_decay={args.weight_decay} å¯èƒ½å¤ªå°ï¼Œæ¨è1e-4åˆ°1e-2')
    
    if args.mamba_layer > 2:
        warnings.append(f'âš ï¸  mamba_layer={args.mamba_layer} å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆï¼Œæ¨è1-2å±‚')
    
    if args.lr > 1e-4:
        warnings.append(f'âš ï¸  lr={args.lr} å¯èƒ½å¤ªå¤§ï¼Œæ¨è1e-5åˆ°1e-4')
    
    if args.scheduler == 'none':
        warnings.append('âš ï¸  æœªä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œæ¨èä½¿ç”¨cosineæˆ–plateau')
    
    if warnings:
        print('ğŸ“‹ Configuration Warnings:')
        for w in warnings:
            print(f'  {w}')
        print()
    
    # ========== å¼€å§‹è®­ç»ƒ ==========
    try:
        if args.eval_only:
            # ä»…è¯„ä¼°æ¨¡å¼
            print(f'\n{"="*80}')
            print('è¯„ä¼°æ¨¡å¼ (Evaluation Only)')
            print(f'{"="*80}\n')
            
            # TODO: å®ç°è¯„ä¼°å‡½æ•°
            print('âš ï¸  è¯„ä¼°æ¨¡å¼å°šæœªå®ç°')
            
        elif args.fold is not None:
            # è®­ç»ƒå•ä¸ªfold
            print(f'\n{"="*80}')
            print(f'è®­ç»ƒå•ä¸ª Fold {args.fold}')
            print(f'{"="*80}\n')
            results = train_survival(args)
            
            # æ‰“å°ç»“æœ
            print(f'\n{"="*80}')
            print(f'âœ… Fold {args.fold} è®­ç»ƒå®Œæˆ!')
            print(f'{"="*80}')
            if results:
                print(f"\nğŸ“Š Results:")
                print(f"  Best Val C-Index: {results.get('best_val_cindex', 0):.4f}")
                print(f"  Final Val C-Index: {results.get('val_cindex', 0):.4f}")
                print(f"  Test C-Index: {results.get('test_cindex', 0):.4f}")
                if results.get('external_cindex') is not None:
                    print(f"  External C-Index: {results['external_cindex']:.4f}")
            print()
            
        else:
            # K-Foldäº¤å‰éªŒè¯
            print(f'\n{"="*80}')
            print(f'å¼€å§‹ {args.k_fold}-Fold äº¤å‰éªŒè¯')
            print(f'{"="*80}\n')
            summary = train_k_fold(args)
            
            # æ‰“å°æ±‡æ€»ç»“æœ
            print(f'\n{"="*80}')
            print(f'âœ… {args.k_fold}-Fold äº¤å‰éªŒè¯å®Œæˆ!')
            print(f'{"="*80}')
            if summary:
                print(f"\nğŸ“Š Summary:")
                print(f"  Val C-Index: {summary.get('mean_val_cindex', 0):.4f} Â± {summary.get('std_val_cindex', 0):.4f}")
                print(f"  Test C-Index: {summary.get('mean_test_cindex', 0):.4f} Â± {summary.get('std_test_cindex', 0):.4f}")
                if summary.get('mean_external_cindex') is not None:
                    print(f"  External C-Index: {summary['mean_external_cindex']:.4f} Â± {summary['std_external_cindex']:.4f}")
                
                # æ‰“å°æ¯ä¸ªfoldçš„ç»“æœ
                print(f"\nğŸ“‹ Per-Fold Results:")
                for i in range(args.k_fold):
                    print(f"  Fold {i}: Val={summary['val_cindices'][i]:.4f}, Test={summary['test_cindices'][i]:.4f}", end='')
                    if summary.get('external_cindices'):
                        print(f", External={summary['external_cindices'][i]:.4f}")
                    else:
                        print()
            print()
            
    except KeyboardInterrupt:
        print('\n\nâŒ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­!')
        sys.exit(0)
    except Exception as e:
        print(f'\n\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}')
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print('='*80)
    print('ğŸ‰ è®­ç»ƒå®Œæˆ!')
    print(f'ğŸ“ ç»“æœä¿å­˜åœ¨: {args.results_dir}')
    print('='*80)


if __name__ == '__main__':
    main()
